#!/usr/bin/env python3
"""
üîç ANALYSE D√âTAILL√âE DE LA QUALIT√â DES DONN√âES
==============================================

Script d'analyse approfondie pour identifier et r√©soudre les probl√®mes de score de qualit√©.
"""

import pandas as pd
import numpy as np
import json
import logging
from pathlib import Path
from typing import Dict, List, Any, Tuple

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class QualityAnalyzer:
    """Analyseur de qualit√© des donn√©es pour identifier les probl√®mes sp√©cifiques."""
    
    def __init__(self):
        self.quality_metrics = {}
        self.problems = []
        self.recommendations = []
    
    def analyze_dataframe(self, df: pd.DataFrame, source_name: str = "unknown") -> Dict[str, Any]:
        """Analyse compl√®te d'un DataFrame pour identifier les probl√®mes de qualit√©."""
        logger.info(f"üîç === ANALYSE DE QUALIT√â: {source_name} ===")
        logger.info(f"üìä Shape: {df.shape[0]} lignes √ó {df.shape[1]} colonnes")
        
        analysis = {
            'source': source_name,
            'shape': df.shape,
            'memory_usage': df.memory_usage(deep=True).sum() / 1024 / 1024,  # MB
            'columns_analysis': {},
            'quality_score': 0.0,
            'problems': [],
            'recommendations': []
        }
        
        # Analyse des colonnes
        for col in df.columns:
            col_analysis = self._analyze_column(df[col], col)
            analysis['columns_analysis'][col] = col_analysis
        
        # Calcul du score global
        analysis['quality_score'] = self._calculate_global_score(analysis['columns_analysis'])
        
        # G√©n√©ration des recommandations
        analysis['recommendations'] = self._generate_recommendations(analysis)
        
        return analysis
    
    def _analyze_column(self, series: pd.Series, col_name: str) -> Dict[str, Any]:
        """Analyse d√©taill√©e d'une colonne."""
        analysis = {
            'name': col_name,
            'dtype': str(series.dtype),
            'null_count': series.isnull().sum(),
            'null_percentage': (series.isnull().sum() / len(series)) * 100,
            'unique_count': series.nunique(),
            'problems': [],
            'score': 100.0
        }
        
        # D√©tection des probl√®mes sp√©cifiques
        problems = []
        
        # 1. Probl√®me de types non-hashables
        if self._has_unhashable_types(series):
            problems.append({
                'type': 'unhashable_types',
                'severity': 'high',
                'description': 'Colonne contient des types dict/list non-hashables',
                'impact': 'Validation limit√©e, score r√©duit'
            })
            analysis['score'] -= 30
        
        # 2. Probl√®me de valeurs manquantes
        if analysis['null_percentage'] > 50:
            problems.append({
                'type': 'high_missing_values',
                'severity': 'medium',
                'description': f"Plus de 50% de valeurs manquantes ({analysis['null_percentage']:.1f}%)",
                'impact': 'Qualit√© des donn√©es compromise'
            })
            analysis['score'] -= 20
        
        # 3. Probl√®me de diversit√© excessive
        if analysis['unique_count'] > len(series) * 0.9:
            problems.append({
                'type': 'low_cardinality',
                'severity': 'low',
                'description': f"Cardinalit√© tr√®s √©lev√©e ({analysis['unique_count']} valeurs uniques)",
                'impact': 'Possible probl√®me de normalisation'
            })
            analysis['score'] -= 10
        
        # 4. Probl√®me de types de donn√©es
        if self._has_inconsistent_types(series):
            problems.append({
                'type': 'inconsistent_types',
                'severity': 'medium',
                'description': 'Types de donn√©es incoh√©rents dans la colonne',
                'impact': 'Validation et traitement limit√©s'
            })
            analysis['score'] -= 15
        
        analysis['problems'] = problems
        analysis['score'] = max(0, analysis['score'])
        
        return analysis
    
    def _has_unhashable_types(self, series: pd.Series) -> bool:
        """V√©rifie si une colonne contient des types non-hashables."""
        try:
            # Test de hashabilit√©
            sample_values = series.dropna().head(100)
            for val in sample_values:
                if isinstance(val, (dict, list, set)):
                    return True
                try:
                    hash(val)
                except (TypeError, ValueError):
                    return True
            return False
        except Exception:
            return True
    
    def _has_inconsistent_types(self, series: pd.Series) -> bool:
        """V√©rifie la coh√©rence des types de donn√©es."""
        try:
            non_null = series.dropna()
            if len(non_null) == 0:
                return False
            
            # V√©rifier la coh√©rence des types
            types = set(type(val) for val in non_null.head(100))
            return len(types) > 1
        except Exception:
            return True
    
    def _calculate_global_score(self, columns_analysis: Dict) -> float:
        """Calcule le score global de qualit√©."""
        if not columns_analysis:
            return 0.0
        
        total_score = sum(col['score'] for col in columns_analysis.values())
        return total_score / len(columns_analysis)
    
    def _generate_recommendations(self, analysis: Dict) -> List[str]:
        """G√©n√®re des recommandations d'am√©lioration."""
        recommendations = []
        
        # Analyse des probl√®mes par type
        problem_types = {}
        for col_name, col_analysis in analysis['columns_analysis'].items():
            for problem in col_analysis['problems']:
                prob_type = problem['type']
                if prob_type not in problem_types:
                    problem_types[prob_type] = []
                problem_types[prob_type].append(col_name)
        
        # Recommandations sp√©cifiques
        if 'unhashable_types' in problem_types:
            cols = problem_types['unhashable_types']
            recommendations.append(f"üîß Normaliser les types complexes dans {len(cols)} colonnes: {', '.join(cols[:5])}")
            recommendations.append("   ‚Üí Convertir dict/list en string avant validation")
            recommendations.append("   ‚Üí Impl√©menter une validation MongoDB-sp√©cifique")
        
        if 'high_missing_values' in problem_types:
            cols = problem_types['high_missing_values']
            recommendations.append(f"üìä Traiter les valeurs manquantes dans {len(cols)} colonnes: {', '.join(cols[:5])}")
            recommendations.append("   ‚Üí Imputation intelligente des valeurs manquantes")
            recommendations.append("   ‚Üí Analyse des patterns de manque")
        
        if 'inconsistent_types' in problem_types:
            cols = problem_types['inconsistent_types']
            recommendations.append(f"üîç Standardiser les types dans {len(cols)} colonnes: {', '.join(cols[:5])}")
            recommendations.append("   ‚Üí Conversion automatique des types")
            recommendations.append("   ‚Üí Validation des conversions")
        
        # Recommandations g√©n√©rales
        if analysis['quality_score'] < 50:
            recommendations.append("üö® Score critique - R√©vision compl√®te de la strat√©gie de validation")
        elif analysis['quality_score'] < 80:
            recommendations.append("‚ö†Ô∏è Score faible - Am√©liorations cibl√©es n√©cessaires")
        else:
            recommendations.append("‚úÖ Score acceptable - Optimisations mineures possibles")
        
        return recommendations
    
    def generate_report(self, analysis: Dict, output_file: str = None) -> str:
        """G√©n√®re un rapport d'analyse d√©taill√©."""
        report = []
        report.append("# üîç RAPPORT D'ANALYSE DE QUALIT√â D√âTAILL√â")
        report.append("")
        report.append(f"## üìä Vue d'ensemble")
        report.append(f"- **Source:** {analysis['source']}")
        report.append(f"- **Shape:** {analysis['shape'][0]} lignes √ó {analysis['shape'][1]} colonnes")
        report.append(f"- **M√©moire:** {analysis['memory_usage']:.2f} MB")
        report.append(f"- **Score global:** {analysis['quality_score']:.2f}%")
        report.append("")
        
        # Probl√®mes identifi√©s
        all_problems = []
        for col_name, col_analysis in analysis['columns_analysis'].items():
            for problem in col_analysis['problems']:
                all_problems.append((col_name, problem))
        
        if all_problems:
            report.append("## üö® Probl√®mes Identifi√©s")
            report.append("")
            for col_name, problem in all_problems:
                report.append(f"### {col_name}")
                report.append(f"- **Type:** {problem['type']}")
                report.append(f"- **S√©v√©rit√©:** {problem['severity']}")
                report.append(f"- **Description:** {problem['description']}")
                report.append(f"- **Impact:** {problem['impact']}")
                report.append("")
        else:
            report.append("## ‚úÖ Aucun probl√®me identifi√©")
            report.append("")
        
        # Analyse des colonnes
        report.append("## üìã Analyse des Colonnes")
        report.append("")
        for col_name, col_analysis in analysis['columns_analysis'].items():
            report.append(f"### {col_name}")
            report.append(f"- **Type:** {col_analysis['dtype']}")
            report.append(f"- **Valeurs manquantes:** {col_analysis['null_count']} ({col_analysis['null_percentage']:.1f}%)")
            report.append(f"- **Valeurs uniques:** {col_analysis['unique_count']}")
            report.append(f"- **Score:** {col_analysis['score']:.1f}%")
            if col_analysis['problems']:
                report.append(f"- **Probl√®mes:** {len(col_analysis['problems'])}")
            report.append("")
        
        # Recommandations
        if analysis['recommendations']:
            report.append("## üí° Recommandations d'Am√©lioration")
            report.append("")
            for rec in analysis['recommendations']:
                report.append(rec)
            report.append("")
        
        report_text = "\n".join(report)
        
        # Sauvegarde du rapport
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(report_text)
            logger.info(f"üìÑ Rapport sauvegard√©: {output_file}")
        
        return report_text

def main():
    """Fonction principale d'analyse de qualit√©."""
    logger.info("üöÄ === D√âMARRAGE ANALYSE DE QUALIT√â ===")
    
    # Cr√©er l'analyseur
    analyzer = QualityAnalyzer()
    
    # Analyser les donn√©es MongoDB export√©es
    csv_file = "exports/trois_rivieres_plex/real_estate_data_modular_pipeline_20250820_200043.csv"
    
    if Path(csv_file).exists():
        logger.info(f"üìÅ Lecture du fichier CSV: {csv_file}")
        df = pd.read_csv(csv_file)
        
        # Analyse compl√®te
        analysis = analyzer.analyze_dataframe(df, "Trois-Rivi√®res Plex (MongoDB)")
        
        # G√©n√©ration du rapport
        output_file = "exports/trois_rivieres_plex/quality_analysis_detailed.md"
        report = analyzer.generate_report(analysis, output_file)
        
        # Affichage du r√©sum√©
        logger.info("üìä === R√âSUM√â DE L'ANALYSE ===")
        logger.info(f"Score global: {analysis['quality_score']:.2f}%")
        logger.info(f"Probl√®mes identifi√©s: {sum(len(col['problems']) for col in analysis['columns_analysis'].values())}")
        logger.info(f"Recommandations: {len(analysis['recommendations'])}")
        
        # Affichage des probl√®mes principaux
        if analysis['recommendations']:
            logger.info("üí° Principales recommandations:")
            for rec in analysis['recommendations'][:3]:
                logger.info(f"  - {rec}")
        
        logger.info(f"üìÑ Rapport d√©taill√©: {output_file}")
        
    else:
        logger.error(f"‚ùå Fichier non trouv√©: {csv_file}")
        logger.info("üí° Ex√©cutez d'abord le pipeline MongoDB pour g√©n√©rer les donn√©es")

if __name__ == "__main__":
    main()
