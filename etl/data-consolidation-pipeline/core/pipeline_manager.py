#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ðŸŽ¼ GESTIONNAIRE PRINCIPAL DU PIPELINE
=====================================

GÃ¨re l'initialisation et l'orchestration du pipeline ETL modulaire
"""

import logging
import time
from typing import Dict, Any, Optional, List
from pathlib import Path
import pandas as pd

# Orchestrateur simple intÃ©grÃ© pour Ã©viter les dÃ©pendances complexes

logger = logging.getLogger(__name__)

class PipelineManager:
    """
    Gestionnaire principal du pipeline ETL modulaire
    
    Responsable de l'initialisation, de la configuration
    et de l'orchestration des composants
    """
    
    def __init__(self, config: Dict = None):
        """
        Initialise le gestionnaire de pipeline
        
        Args:
            config: Configuration du pipeline
        """
        self.config = config or {}
        self.start_time = None
        self.end_time = None
        
        # === INITIALISATION DE L'ORCHESTRATEUR INTÃ‰GRÃ‰ ===
        logger.info("ðŸŽ¼ === INITIALISATION ORCHESTRATEUR INTÃ‰GRÃ‰ ===")
        try:
            # CrÃ©ation d'un orchestrateur intÃ©grÃ©
            self.orchestrator = self._create_integrated_orchestrator()
            logger.info("âœ… Orchestrateur intÃ©grÃ© initialisÃ©")
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation orchestrateur: {e}")
            raise
        
        # === INITIALISATION DES MODULES EXTERNES ===
        self._initialize_external_modules()
        
        logger.info("âœ… Pipeline initialisÃ© avec succÃ¨s")
    
    def _create_integrated_orchestrator(self):
        """CrÃ©e un orchestrateur intÃ©grÃ© pour le pipeline modulaire"""
        class IntegratedOrchestrator:
            def __init__(self):
                self.data_extractor = self._create_data_extractor()
                self.pipeline_version = '7.0.0_modular'
                self.optimization_level = 'medium'
            
            def _create_data_extractor(self):
                """CrÃ©e un extracteur de donnÃ©es intÃ©grÃ©"""
                class DataExtractor:
                    def extract_data(self, source: str, source_config: Dict):
                        if source == "test":
                            return self._generate_test_data()
                        elif source == "mongodb":
                            return self._extract_mongodb(source_config)
                        else:
                            return {"dataframe": pd.DataFrame()}
                    
                    def _generate_test_data(self):
                        """GÃ©nÃ¨re des donnÃ©es de test"""
                        import numpy as np
                        np.random.seed(42)
                        num_properties = 1000
                        
                        data = {
                            'price': np.random.uniform(200000, 2000000, num_properties),
                            'prix': np.random.uniform(200000, 2000000, num_properties),
                            'surface': np.random.uniform(50, 500, num_properties),
                            'superficie': np.random.uniform(50, 500, num_properties),
                            'bedrooms': np.random.randint(1, 6, num_properties),
                            'chambres': np.random.randint(1, 6, num_properties),
                            'bathrooms': np.random.randint(1, 4, num_properties),
                            'salle_bain': np.random.randint(1, 4, num_properties),
                            'latitude': np.random.uniform(45.0, 46.0, num_properties),
                            'longitude': np.random.uniform(-74.0, -73.0, num_properties),
                            'city': np.random.choice(['MontrÃ©al', 'QuÃ©bec', 'Laval', 'Gatineau'], num_properties),
                            'type': np.random.choice(['Maison', 'Appartement', 'Condo', 'Duplex'], num_properties),
                            'year_built': np.random.randint(1950, 2024, num_properties),
                            'annee_construction': np.random.randint(1950, 2024, num_properties)
                        }
                        
                        df = pd.DataFrame(data)
                        return {"dataframe": df}
                    
                    def _extract_mongodb(self, source_config: Dict):
                        """Extraction MongoDB intÃ©grÃ©e"""
                        try:
                            import pymongo
                            
                            # Connexion MongoDB
                            client = pymongo.MongoClient("mongodb://localhost:27017/")
                            db = client[source_config.get('database', 'real_estate_db')]
                            collection = db[source_config.get('collection', 'properties')]
                            
                            # RequÃªte
                            query = source_config.get('query', {})
                            limit = source_config.get('limit', 1000)
                            
                            # Extraction
                            cursor = collection.find(query).limit(limit)
                            data = list(cursor)
                            
                            if data:
                                df = pd.DataFrame(data)
                                # Conversion des ObjectId en string
                                if '_id' in df.columns:
                                    df['_id'] = df['_id'].astype(str)
                                
                                logger.info(f"âœ… MongoDB: {len(df)} documents extraits")
                                client.close()
                                return {"dataframe": df}
                            else:
                                logger.warning("âš ï¸ Aucun document trouvÃ© dans MongoDB")
                                client.close()
                                return {"dataframe": pd.DataFrame()}
                                
                        except Exception as e:
                            logger.error(f"âŒ Erreur extraction MongoDB: {e}")
                            return {"dataframe": pd.DataFrame()}
                
                return DataExtractor()
            
            def run_modular_pipeline_only(self, input_source: str, input_config: Dict, 
                                         output_config: Dict) -> Dict[str, Any]:
                """ExÃ©cute le pipeline modulaire intÃ©grÃ©"""
                logger.info("ðŸŽ¼ === EXÃ‰CUTION PIPELINE MODULAIRE INTÃ‰GRÃ‰ ===")
                
                try:
                    # RÃ©cupÃ©ration des donnÃ©es d'entrÃ©e
                    if input_source == "dataframe" and "dataframe" in input_config:
                        df = input_config["dataframe"]
                        logger.info(f"ðŸ“Š Traitement de {len(df)} lignes Ã— {len(df.columns)} colonnes")
                        
                        # Traitement intÃ©grÃ© (consolidation avancÃ©e)
                        df_processed = self._process_data(df)
                        
                        # Ajout de mÃ©tadonnÃ©es de traitement
                        df_processed.attrs['pipeline_version'] = self.pipeline_version
                        df_processed.attrs['optimization_level'] = self.optimization_level
                        df_processed.attrs['processed'] = True
                        
                        logger.info("âœ… Pipeline modulaire intÃ©grÃ© terminÃ©")
                        
                        return {
                            'status': 'success',
                            'final_dataframe': df_processed,
                            'processing_info': {
                                'pipeline_version': self.pipeline_version,
                                'optimization_level': self.optimization_level,
                                'input_shape': df.shape,
                                'output_shape': df_processed.shape
                            }
                        }
                    else:
                        logger.error(f"âŒ Source d'entrÃ©e non supportÃ©e: {input_source}")
                        return {
                            'status': 'error',
                            'error': f'Source non supportÃ©e: {input_source}'
                        }
                        
                except Exception as e:
                    logger.error(f"âŒ Erreur pipeline modulaire intÃ©grÃ©: {e}")
                    return {
                        'status': 'error',
                        'error': str(e)
                    }
            
            def _process_data(self, df: pd.DataFrame) -> pd.DataFrame:
                """Traitement intÃ©grÃ© des donnÃ©es (consolidation avancÃ©e)"""
                logger.info("ðŸ”§ Traitement des donnÃ©es...")
                df_processed = df.copy()
                
                # === STRATÃ‰GIE DE CONSOLIDATION INTELLIGENTE ===
                logger.info("ðŸ§  Application de la stratÃ©gie de consolidation intelligente...")
                
                # RÃ¨gles de consolidation complÃ¨tes
                consolidation_rules = [
                    # Groupe revenus
                    (['plex-revenue', 'revenu', 'plex-revenu', 'potential_gross_revenue'], 'revenue_final'),
                    # Groupe adresses
                    (['address', 'full_address', 'location'], 'address_final'),
                    # Groupe prix
                    (['price_assessment', 'price_final', 'price', 'prix'], 'price_final'),
                    # Groupe surfaces
                    (['living_area', 'surface_final', 'surface', 'superficie'], 'surface_final'),
                    # Groupe chambres
                    (['nb_bedroom', 'bedrooms_final', 'bedroom', 'chambres'], 'bedrooms_final'),
                    # Groupe salles de bain
                    (['nb_bathroom', 'bathrooms_final', 'bathroom', 'salle_bain'], 'bathrooms_final'),
                    # Groupe annÃ©e construction
                    (['construction_year', 'year_built_final', 'year_built', 'annee'], 'year_built_final'),
                    # Groupe taxes municipales
                    (['municipal_taxes', 'municipal_tax', 'taxes_municipales'], 'municipal_taxes_final'),
                    # Groupe taxes scolaires
                    (['school_taxes', 'school_tax', 'taxes_scolaires'], 'school_taxes_final'),
                    # Groupe Ã©valuations municipales
                    (['municipal_evaluation_building', 'municipal_evaluation_land', 'municipal_evaluation_total'], 'municipal_evaluation_final')
                ]
                
                # Application de la consolidation intelligente
                columns_consolidated = 0
                for source_cols, target_col in consolidation_rules:
                    # Filtrer les colonnes disponibles
                    available_cols = [col for col in source_cols if col in df_processed.columns]
                    
                    if len(available_cols) > 1:
                        logger.info(f"ðŸ”„ Consolidation: {available_cols} â†’ {target_col}")
                        
                        # StratÃ©gie de consolidation intelligente
                        df_processed[target_col] = self._consolidate_columns_intelligently(df_processed, available_cols)
                        
                        # Supprimer les colonnes sources
                        df_processed = df_processed.drop(columns=available_cols)
                        columns_consolidated += len(available_cols)
                        
                        logger.info(f"âœ… {len(available_cols)} colonnes consolidÃ©es dans {target_col}")
                    elif len(available_cols) == 1:
                        # Renommer la colonne unique
                        df_processed = df_processed.rename(columns={available_cols[0]: target_col})
                        logger.info(f"ðŸ”„ Renommage: {available_cols[0]} â†’ {target_col}")
                
                # === CONSOLIDATION INTELLIGENTE DES STRUCTURES COMPLEXES ===
                logger.info("ðŸ§  Application de la consolidation intelligente des structures complexes...")
                
                # Consolidation intelligente des unitÃ©s
                df_processed = self._consolidate_units_intelligently(df_processed)
                
                # Consolidation intelligente des adresses
                df_processed = self._consolidate_address_intelligently(df_processed)
                
                # Calcul des mÃ©triques de consolidation
                original_columns = len(df.columns)
                final_columns = len(df_processed.columns)
                reduction = original_columns - final_columns
                reduction_percentage = (reduction / original_columns) * 100 if original_columns > 0 else 0
                
                logger.info(f"ðŸ“Š === RÃ‰SULTATS DE LA CONSOLIDATION ===")
                logger.info(f"Colonnes originales: {original_columns}")
                logger.info(f"Colonnes finales: {final_columns}")
                logger.info(f"Colonnes consolidÃ©es: {columns_consolidated}")
                logger.info(f"RÃ©duction: {reduction} colonnes ({reduction_percentage:.1f}%)")
                
                logger.info(f"âœ… DonnÃ©es traitÃ©es: {df_processed.shape[0]} lignes Ã— {df_processed.shape[1]} colonnes")
                return df_processed
            
            def _consolidate_columns_intelligently(self, df: pd.DataFrame, source_columns: List[str]) -> pd.Series:
                """Consolidation intelligente des colonnes avec stratÃ©gie de prioritÃ©."""
                if not source_columns:
                    return pd.Series(dtype='object')
                
                # StratÃ©gie de prioritÃ© basÃ©e sur le nom de la colonne
                priority_order = {
                    'revenue': ['plex-revenue', 'revenu', 'potential_gross_revenue'],
                    'address': ['address', 'full_address', 'location'],
                    'price': ['price_final', 'price_assessment', 'price', 'prix'],
                    'surface': ['surface_final', 'living_area', 'surface', 'superficie'],
                    'bedrooms': ['bedrooms_final', 'nb_bedroom', 'bedroom', 'chambres'],
                    'bathrooms': ['bathrooms_final', 'nb_bathroom', 'bathroom', 'salle_bain'],
                    'year': ['year_built_final', 'construction_year', 'year_built', 'annee'],
                    'taxes': ['municipal_taxes', 'municipal_tax', 'taxes_municipales'],
                    'school': ['school_taxes', 'school_tax', 'taxes_scolaires'],
                    'evaluation': ['municipal_evaluation_total', 'municipal_evaluation_building', 'municipal_evaluation_land']
                }
                
                # DÃ©terminer le type de consolidation
                consolidation_type = None
                for key, priority_list in priority_order.items():
                    if any(col in source_columns for col in priority_list):
                        consolidation_type = key
                        break
                
                if consolidation_type and consolidation_type in priority_order:
                    # Appliquer l'ordre de prioritÃ©
                    for priority_col in priority_order[consolidation_type]:
                        if priority_col in source_columns:
                            logger.info(f"ðŸŽ¯ PrioritÃ©: {priority_col} pour {consolidation_type}")
                            return df[priority_col]
                
                # Fallback: premiÃ¨re colonne non-nulle
                for col in source_columns:
                    if col in df.columns and not df[col].isna().all():
                        logger.info(f"ðŸ”„ Fallback: {col}")
                        return df[col]
                
                # Dernier fallback: premiÃ¨re colonne disponible
                return df[source_columns[0]]
            
            def _consolidate_units_intelligently(self, df: pd.DataFrame) -> pd.DataFrame:
                """Consolidation intelligente des colonnes d'unitÃ©s."""
                logger.info("ðŸ  === CONSOLIDATION INTELLIGENTE DES UNITÃ‰S ===")
                
                df_consolidated = df.copy()
                
                # Colonnes sources pour les unitÃ©s
                unit_columns = ['unites', 'residential_units', 'commercial_units']
                available_columns = [col for col in unit_columns if col in df.columns]
                
                # Correction: utilisation de len() sur une liste Python pure
                if len(available_columns) > 1:
                    logger.info(f"ðŸ”„ Consolidation intelligente des colonnes d'unitÃ©s: {available_columns}")
                    
                    # CrÃ©er les colonnes consolidÃ©es
                    df_consolidated['total_units_final'] = self._calculate_total_units(df, available_columns)
                    df_consolidated['unit_types_final'] = self._extract_unit_types(df, available_columns)
                    df_consolidated['unit_details_final'] = self._create_unit_details(df, available_columns)
                    
                    # Supprimer les colonnes sources
                    df_consolidated = df_consolidated.drop(columns=available_columns)
                    
                    logger.info(f"âœ… {len(available_columns)} colonnes d'unitÃ©s consolidÃ©es intelligemment")
                
                return df_consolidated
            
            def _consolidate_address_intelligently(self, df: pd.DataFrame) -> pd.DataFrame:
                """Consolidation intelligente des colonnes d'adresses."""
                logger.info("ðŸ  === CONSOLIDATION INTELLIGENTE DES ADRESSES ===")
                
                df_consolidated = df.copy()
                
                # Colonnes sources pour les adresses
                address_columns = ['address', 'full_address', 'location']
                available_columns = [col for col in address_columns if col in df.columns]
                
                # Correction: utilisation de len() sur une liste Python pure
                if len(available_columns) > 1:
                    logger.info(f"ðŸ”„ Consolidation intelligente des colonnes d'adresses: {available_columns}")
                    
                    # CrÃ©er les colonnes consolidÃ©es
                    df_consolidated['street_final'] = self._extract_street(df, available_columns)
                    df_consolidated['city_final'] = self._extract_city(df, available_columns)
                    df_consolidated['postal_code_final'] = self._extract_postal_code(df, available_columns)
                    
                    # Supprimer les colonnes sources
                    df_consolidated = df_consolidated.drop(columns=available_columns)
                    
                    logger.info(f"âœ… {len(available_columns)} colonnes d'adresses consolidÃ©es intelligemment")
                
                return df_consolidated
            
            def _parse_json_string(self, value):
                """Parse une chaÃ®ne JSON de maniÃ¨re sÃ©curisÃ©e."""
                if pd.isna(value) or value == '':
                    return None
                
                # Si c'est dÃ©jÃ  une liste ou un dict Python, le retourner directement
                if isinstance(value, (list, dict)):
                    return value
                
                # Si c'est une chaÃ®ne, essayer de la parser
                if isinstance(value, str):
                    try:
                        # Essayer d'abord json.loads
                        import json
                        return json.loads(value)
                    except json.JSONDecodeError:
                        try:
                            # Fallback: ast.literal_eval pour les structures Python
                            import ast
                            return ast.literal_eval(value)
                        except (ValueError, SyntaxError):
                            # Dernier fallback: traiter comme string
                            return value
                
                # Pour tout autre type, retourner tel quel
                return value
            
            def _calculate_total_units(self, df: pd.DataFrame, unit_columns: List[str]) -> pd.Series:
                """Calcule le nombre total d'unitÃ©s."""
                total_units = pd.Series(0, index=df.index)
                
                for col in unit_columns:
                    if col in df.columns:
                        for idx, value in df[col].items():
                            if pd.notna(value):
                                parsed_value = self._parse_json_string(value)
                                if isinstance(parsed_value, list):
                                    # Compter les unitÃ©s dans la liste
                                    count = 0
                                    for item in parsed_value:
                                        if isinstance(item, dict):
                                            # Extraire le count ou nb_unite
                                            if 'count' in item:
                                                try:
                                                    count += int(str(item['count']).strip())
                                                except (ValueError, TypeError):
                                                    count += 1
                                            elif 'nb_unite' in item:
                                                try:
                                                    count += int(str(item['nb_unite']).strip())
                                                except (ValueError, TypeError):
                                                    count += 1
                                            else:
                                                count += 1
                                        else:
                                            count += 1
                                    total_units[idx] += count
                                elif isinstance(parsed_value, dict):
                                    # Structure simple
                                    if 'count' in parsed_value:
                                        try:
                                            total_units[idx] += int(str(parsed_value['count']).strip())
                                        except (ValueError, TypeError):
                                            total_units[idx] += 1
                                    elif 'nb_unite' in parsed_value:
                                        try:
                                            total_units[idx] += int(str(parsed_value['nb_unite']).strip())
                                        except (ValueError, TypeError):
                                            total_units[idx] += 1
                
                return total_units
            
            def _extract_unit_types(self, df: pd.DataFrame, unit_columns: List[str]) -> pd.Series:
                """Extrait les types d'unitÃ©s uniques."""
                unit_types = pd.Series('', index=df.index)
                
                for col in unit_columns:
                    if col in df.columns:
                        for idx, value in df[col].items():
                            # Correction: utilisation de mÃ©thodes pandas appropriÃ©es
                            current_value = unit_types.iloc[idx]
                            if pd.notna(value) and (current_value == '' or pd.isna(current_value)):
                                parsed_value = self._parse_json_string(value)
                                if isinstance(parsed_value, list):
                                    types = []
                                    for item in parsed_value:
                                        if isinstance(item, dict):
                                            # Extraire le type ou unite
                                            if 'type' in item:
                                                types.append(str(item['type']))
                                            elif 'unite' in item:
                                                types.append(str(item['unite']))
                                    if types:
                                        unit_types.iloc[idx] = ', '.join(set(types))
                                elif isinstance(parsed_value, dict):
                                    if 'type' in parsed_value:
                                        unit_types.iloc[idx] = str(parsed_value['type'])
                                    elif 'unite' in parsed_value:
                                        unit_types.iloc[idx] = str(parsed_value['unite'])
                
                return unit_types
            
            def _create_unit_details(self, df: pd.DataFrame, unit_columns: List[str]) -> pd.Series:
                """CrÃ©e une structure dÃ©taillÃ©e des unitÃ©s."""
                unit_details = pd.Series('', index=df.index)
                
                for col in unit_columns:
                    if col in df.columns:
                        for idx, value in df[col].items():
                            # Correction: utilisation de mÃ©thodes pandas appropriÃ©es
                            current_value = unit_details.iloc[idx]
                            if pd.notna(value) and (current_value == '' or pd.isna(current_value)):
                                parsed_value = self._parse_json_string(value)
                                if isinstance(parsed_value, list):
                                    details = []
                                    for item in parsed_value:
                                        if isinstance(item, dict):
                                            detail = {}
                                            if 'type' in item:
                                                detail['type'] = item['type']
                                            elif 'unite' in item:
                                                detail['type'] = item['unite']
                                            
                                            if 'count' in item:
                                                detail['count'] = item['count']
                                            elif 'nb_unite' in item:
                                                detail['count'] = item['nb_unite']
                                            
                                            if detail:
                                                details.append(detail)
                                    
                                    if details:
                                        import json
                                        unit_details.iloc[idx] = json.dumps(details, ensure_ascii=False)
                                elif isinstance(parsed_value, dict):
                                    detail = {}
                                    if 'type' in parsed_value:
                                        detail['type'] = parsed_value['type']
                                    elif 'unite' in parsed_value:
                                        detail['type'] = parsed_value['unite']
                                    
                                    if 'count' in parsed_value:
                                        detail['count'] = parsed_value['count']
                                    elif 'nb_unite' in parsed_value:
                                        detail['count'] = parsed_value['nb_unite']
                                    
                                    if detail:
                                        import json
                                        unit_details.iloc[idx] = json.dumps([detail], ensure_ascii=False)
                
                return unit_details
            
            def _extract_street(self, df: pd.DataFrame, address_columns: List[str]) -> pd.Series:
                """Extrait la rue depuis les colonnes d'adresse."""
                street = pd.Series('', index=df.index)
                
                for col in address_columns:
                    if col in df.columns:
                        for idx, value in df[col].items():
                            # Correction: utilisation de mÃ©thodes pandas appropriÃ©es
                            current_value = street.iloc[idx]
                            if pd.notna(value) and (current_value == '' or pd.isna(current_value)):
                                parsed_value = self._parse_json_string(value)
                                if isinstance(parsed_value, dict):
                                    if 'street' in parsed_value:
                                        street.iloc[idx] = str(parsed_value['street'])
                                elif isinstance(parsed_value, str):
                                    # Essayer d'extraire la rue d'une adresse complÃ¨te
                                    if ',' in parsed_value:
                                        street.iloc[idx] = parsed_value.split(',')[0].strip()
                                    else:
                                        street.iloc[idx] = parsed_value
                
                return street
            
            def _extract_city(self, df: pd.DataFrame, address_columns: List[str]) -> pd.Series:
                """Extrait la ville depuis les colonnes d'adresse."""
                city = pd.Series('', index=df.index)
                
                for col in address_columns:
                    if col in address_columns:
                        for idx, value in df[col].items():
                            # Correction: utilisation de mÃ©thodes pandas appropriÃ©es
                            current_value = city.iloc[idx]
                            if pd.notna(value) and (current_value == '' or pd.isna(current_value)):
                                parsed_value = self._parse_json_string(value)
                                if isinstance(parsed_value, dict):
                                    if 'locality' in parsed_value:
                                        city.iloc[idx] = str(parsed_value['locality'])
                                elif isinstance(parsed_value, str):
                                    # Essayer d'extraire la ville d'une adresse complÃ¨te
                                    if ',' in parsed_value:
                                        parts = parsed_value.split(',')
                                        if len(parts) > 1:
                                            city.iloc[idx] = parts[1].strip()
                
                return city
            
            def _extract_postal_code(self, df: pd.DataFrame, address_columns: List[str]) -> pd.Series:
                """Extrait le code postal depuis les colonnes d'adresse."""
                postal_code = pd.Series('', index=df.index)
                
                for col in address_columns:
                    if col in address_columns:
                        for idx, value in df[col].items():
                            # Correction: utilisation de mÃ©thodes pandas appropriÃ©es
                            current_value = postal_code.iloc[idx]
                            if pd.notna(value) and (current_value == '' or pd.isna(current_value)):
                                parsed_value = self._parse_json_string(value)
                                if isinstance(parsed_value, dict):
                                    if 'postal_code' in parsed_value:
                                        postal_code.iloc[idx] = str(parsed_value['postal_code'])
                
                return postal_code
            
            def get_status(self) -> Dict[str, Any]:
                """Retourne le statut de l'orchestrateur"""
                return {
                    'pipeline_version': self.pipeline_version,
                    'optimization_level': self.optimization_level,
                    'status': 'ready',
                    'type': 'integrated'
                }
        
        return IntegratedOrchestrator()
    
    def _initialize_external_modules(self):
        """Initialise les modules externes disponibles"""
        logger.info("ðŸ”§ Initialisation des modules externes...")
        
        # === SIMILARITY DETECTOR ===
        try:
            from intelligence.similarity_detector import SimilarityDetector
            self.similarity_detector = SimilarityDetector()
            logger.info("âœ… DÃ©tecteur de similaritÃ© initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ SimilarityDetector non disponible")
            self.similarity_detector = None
        
        # === QUALITY VALIDATOR ===
        try:
            from validation.quality_validator import QualityValidator
            self.quality_validator = QualityValidator()
            logger.info("âœ… Validateur de qualitÃ© initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ QualityValidator non disponible")
            self.quality_validator = None
        
        # === ADVANCED EXPORTER ===
        try:
            from export.advanced_exporter import AdvancedExporter
            self.exporter = AdvancedExporter()
            logger.info("âœ… Exportateur avancÃ© initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ AdvancedExporter non disponible")
            self.exporter = None
        
        # === PERFORMANCE OPTIMIZER ===
        try:
            from performance.performance_optimizer import PerformanceOptimizer
            self.performance_optimizer = PerformanceOptimizer()
            self.performance_optimizer.enable_all_optimizations()
            logger.info("âœ… Optimiseur de performance initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ PerformanceOptimizer non disponible")
            self.performance_optimizer = None
        
        # === PROPERTY TYPE NORMALIZER ===
        try:
            from utils.property_type_normalizer import PropertyTypeNormalizer
            self.property_normalizer = PropertyTypeNormalizer()
            logger.info("âœ… Normaliseur de types de propriÃ©tÃ©s initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ PropertyTypeNormalizer non disponible")
            self.property_normalizer = None
        
        # === VALIDATION DASHBOARD ===
        try:
            from dashboard.validation_dashboard import ValidationDashboard
            self.validation_dashboard = ValidationDashboard()
            logger.info("âœ… Dashboard de validation initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ ValidationDashboard non disponible")
            self.validation_dashboard = None
    
    def start_pipeline(self):
        """DÃ©marre le pipeline et enregistre le temps de dÃ©but"""
        self.start_time = time.time()
        logger.info("ðŸš€ === DÃ‰MARRAGE DU PIPELINE MODULAIRE ===")
    
    def end_pipeline(self):
        """Termine le pipeline et calcule la durÃ©e"""
        self.end_time = time.time()
        duration = self.end_time - self.start_time if self.start_time else 0
        logger.info(f"â±ï¸ DurÃ©e totale: {duration:.2f} secondes")
        return duration
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """Retourne le statut actuel du pipeline"""
        return {
            "start_time": self.start_time,
            "end_time": self.end_time,
            "duration": (self.end_time - self.start_time) if self.start_time and self.end_time else 0,
            "orchestrator_ready": hasattr(self, 'orchestrator') and self.orchestrator is not None,
            "external_modules": {
                "similarity_detector": self.similarity_detector is not None,
                "quality_validator": self.quality_validator is not None,
                "exporter": self.exporter is not None,
                "performance_optimizer": self.performance_optimizer is not None,
                "property_normalizer": self.property_normalizer is not None,
                "validation_dashboard": self.validation_dashboard is not None
            }
        }
