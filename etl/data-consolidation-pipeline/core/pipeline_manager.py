#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ðŸŽ¼ GESTIONNAIRE PRINCIPAL DU PIPELINE
=====================================

GÃ¨re l'initialisation et l'orchestration du pipeline ETL modulaire
"""

import logging
import time
from typing import Dict, Any, Optional
from pathlib import Path
import pandas as pd

# Orchestrateur simple intÃ©grÃ© pour Ã©viter les dÃ©pendances complexes

logger = logging.getLogger(__name__)

class PipelineManager:
    """
    Gestionnaire principal du pipeline ETL modulaire
    
    Responsable de l'initialisation, de la configuration
    et de l'orchestration des composants
    """
    
    def __init__(self, config: Dict = None):
        """
        Initialise le gestionnaire de pipeline
        
        Args:
            config: Configuration du pipeline
        """
        self.config = config or {}
        self.start_time = None
        self.end_time = None
        
        # === INITIALISATION DE L'ORCHESTRATEUR INTÃ‰GRÃ‰ ===
        logger.info("ðŸŽ¼ === INITIALISATION ORCHESTRATEUR INTÃ‰GRÃ‰ ===")
        try:
            # CrÃ©ation d'un orchestrateur intÃ©grÃ©
            self.orchestrator = self._create_integrated_orchestrator()
            logger.info("âœ… Orchestrateur intÃ©grÃ© initialisÃ©")
        except Exception as e:
            logger.error(f"âŒ Erreur initialisation orchestrateur: {e}")
            raise
        
        # === INITIALISATION DES MODULES EXTERNES ===
        self._initialize_external_modules()
        
        logger.info("âœ… Pipeline initialisÃ© avec succÃ¨s")
    
    def _create_integrated_orchestrator(self):
        """CrÃ©e un orchestrateur intÃ©grÃ© pour le pipeline modulaire"""
        class IntegratedOrchestrator:
            def __init__(self):
                self.data_extractor = self._create_data_extractor()
                self.pipeline_version = '7.0.0_modular'
                self.optimization_level = 'medium'
            
            def _create_data_extractor(self):
                """CrÃ©e un extracteur de donnÃ©es intÃ©grÃ©"""
                class DataExtractor:
                    def extract_data(self, source: str, source_config: Dict):
                        if source == "test":
                            return self._generate_test_data()
                        elif source == "mongodb":
                            return self._extract_mongodb(source_config)
                        else:
                            return {"dataframe": pd.DataFrame()}
                    
                    def _generate_test_data(self):
                        """GÃ©nÃ¨re des donnÃ©es de test"""
                        import numpy as np
                        np.random.seed(42)
                        num_properties = 1000
                        
                        data = {
                            'price': np.random.uniform(200000, 2000000, num_properties),
                            'prix': np.random.uniform(200000, 2000000, num_properties),
                            'surface': np.random.uniform(50, 500, num_properties),
                            'superficie': np.random.uniform(50, 500, num_properties),
                            'bedrooms': np.random.randint(1, 6, num_properties),
                            'chambres': np.random.randint(1, 6, num_properties),
                            'bathrooms': np.random.randint(1, 4, num_properties),
                            'salle_bain': np.random.randint(1, 4, num_properties),
                            'latitude': np.random.uniform(45.0, 46.0, num_properties),
                            'longitude': np.random.uniform(-74.0, -73.0, num_properties),
                            'city': np.random.choice(['MontrÃ©al', 'QuÃ©bec', 'Laval', 'Gatineau'], num_properties),
                            'type': np.random.choice(['Maison', 'Appartement', 'Condo', 'Duplex'], num_properties),
                            'year_built': np.random.randint(1950, 2024, num_properties),
                            'annee_construction': np.random.randint(1950, 2024, num_properties)
                        }
                        
                        df = pd.DataFrame(data)
                        return {"dataframe": df}
                    
                    def _extract_mongodb(self, source_config: Dict):
                        """Extraction MongoDB intÃ©grÃ©e"""
                        try:
                            import pymongo
                            
                            # Connexion MongoDB
                            client = pymongo.MongoClient("mongodb://localhost:27017/")
                            db = client[source_config.get('database', 'real_estate_db')]
                            collection = db[source_config.get('collection', 'properties')]
                            
                            # RequÃªte
                            query = source_config.get('query', {})
                            limit = source_config.get('limit', 1000)
                            
                            # Extraction
                            cursor = collection.find(query).limit(limit)
                            data = list(cursor)
                            
                            if data:
                                df = pd.DataFrame(data)
                                # Conversion des ObjectId en string
                                if '_id' in df.columns:
                                    df['_id'] = df['_id'].astype(str)
                                
                                logger.info(f"âœ… MongoDB: {len(df)} documents extraits")
                                client.close()
                                return {"dataframe": df}
                            else:
                                logger.warning("âš ï¸ Aucun document trouvÃ© dans MongoDB")
                                client.close()
                                return {"dataframe": pd.DataFrame()}
                                
                        except Exception as e:
                            logger.error(f"âŒ Erreur extraction MongoDB: {e}")
                            return {"dataframe": pd.DataFrame()}
                
                return DataExtractor()
            
            def run_modular_pipeline_only(self, input_source: str, input_config: Dict, 
                                         output_config: Dict) -> Dict[str, Any]:
                """ExÃ©cute le pipeline modulaire intÃ©grÃ©"""
                logger.info("ðŸŽ¼ === EXÃ‰CUTION PIPELINE MODULAIRE INTÃ‰GRÃ‰ ===")
                
                try:
                    # RÃ©cupÃ©ration des donnÃ©es d'entrÃ©e
                    if input_source == "dataframe" and "dataframe" in input_config:
                        df = input_config["dataframe"]
                        logger.info(f"ðŸ“Š Traitement de {len(df)} lignes Ã— {len(df.columns)} colonnes")
                        
                        # Traitement intÃ©grÃ© (consolidation avancÃ©e)
                        df_processed = self._process_data(df)
                        
                        # Ajout de mÃ©tadonnÃ©es de traitement
                        df_processed.attrs['pipeline_version'] = self.pipeline_version
                        df_processed.attrs['optimization_level'] = self.optimization_level
                        df_processed.attrs['processed'] = True
                        
                        logger.info("âœ… Pipeline modulaire intÃ©grÃ© terminÃ©")
                        
                        return {
                            'status': 'success',
                            'final_dataframe': df_processed,
                            'processing_info': {
                                'pipeline_version': self.pipeline_version,
                                'optimization_level': self.optimization_level,
                                'input_shape': df.shape,
                                'output_shape': df_processed.shape
                            }
                        }
                    else:
                        logger.error(f"âŒ Source d'entrÃ©e non supportÃ©e: {input_source}")
                        return {
                            'status': 'error',
                            'error': f'Source non supportÃ©e: {input_source}'
                        }
                        
                except Exception as e:
                    logger.error(f"âŒ Erreur pipeline modulaire intÃ©grÃ©: {e}")
                    return {
                        'status': 'error',
                        'error': str(e)
                    }
            
            def _process_data(self, df: pd.DataFrame) -> pd.DataFrame:
                """Traitement intÃ©grÃ© des donnÃ©es (consolidation avancÃ©e)"""
                logger.info("ðŸ”§ Traitement des donnÃ©es...")
                
                df_processed = df.copy()
                
                # Consolidation avancÃ©e des colonnes similaires
                consolidation_rules = [
                    (['price', 'prix'], 'price_final'),
                    (['surface', 'superficie'], 'surface_final'),
                    (['bedrooms', 'chambres'], 'bedrooms_final'),
                    (['bathrooms', 'salle_bain'], 'bathrooms_final'),
                    (['year_built', 'annee_construction'], 'year_built_final')
                ]
                
                for source_cols, target_col in consolidation_rules:
                    available_cols = [col for col in source_cols if col in df_processed.columns]
                    if available_cols:
                        # Prendre la premiÃ¨re colonne non-nulle
                        df_processed[target_col] = df_processed[available_cols].bfill(axis=1).iloc[:, 0]
                        # Supprimer les colonnes sources
                        df_processed = df_processed.drop(columns=available_cols)
                
                logger.info(f"âœ… DonnÃ©es traitÃ©es: {df_processed.shape[0]} lignes Ã— {df_processed.shape[1]} colonnes")
                return df_processed
            
            def get_status(self) -> Dict[str, Any]:
                """Retourne le statut de l'orchestrateur"""
                return {
                    'pipeline_version': self.pipeline_version,
                    'optimization_level': self.optimization_level,
                    'status': 'ready',
                    'type': 'integrated'
                }
        
        return IntegratedOrchestrator()
    
    def _initialize_external_modules(self):
        """Initialise les modules externes disponibles"""
        logger.info("ðŸ”§ Initialisation des modules externes...")
        
        # === SIMILARITY DETECTOR ===
        try:
            from intelligence.similarity_detector import SimilarityDetector
            self.similarity_detector = SimilarityDetector()
            logger.info("âœ… DÃ©tecteur de similaritÃ© initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ SimilarityDetector non disponible")
            self.similarity_detector = None
        
        # === QUALITY VALIDATOR ===
        try:
            from validation.quality_validator import QualityValidator
            self.quality_validator = QualityValidator()
            logger.info("âœ… Validateur de qualitÃ© initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ QualityValidator non disponible")
            self.quality_validator = None
        
        # === ADVANCED EXPORTER ===
        try:
            from export.advanced_exporter import AdvancedExporter
            self.exporter = AdvancedExporter()
            logger.info("âœ… Exportateur avancÃ© initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ AdvancedExporter non disponible")
            self.exporter = None
        
        # === PERFORMANCE OPTIMIZER ===
        try:
            from performance.performance_optimizer import PerformanceOptimizer
            self.performance_optimizer = PerformanceOptimizer()
            self.performance_optimizer.enable_all_optimizations()
            logger.info("âœ… Optimiseur de performance initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ PerformanceOptimizer non disponible")
            self.performance_optimizer = None
        
        # === PROPERTY TYPE NORMALIZER ===
        try:
            from utils.property_type_normalizer import PropertyTypeNormalizer
            self.property_normalizer = PropertyTypeNormalizer()
            logger.info("âœ… Normaliseur de types de propriÃ©tÃ©s initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ PropertyTypeNormalizer non disponible")
            self.property_normalizer = None
        
        # === VALIDATION DASHBOARD ===
        try:
            from dashboard.validation_dashboard import ValidationDashboard
            self.validation_dashboard = ValidationDashboard()
            logger.info("âœ… Dashboard de validation initialisÃ©")
        except ImportError:
            logger.warning("âš ï¸ ValidationDashboard non disponible")
            self.validation_dashboard = None
    
    def start_pipeline(self):
        """DÃ©marre le pipeline et enregistre le temps de dÃ©but"""
        self.start_time = time.time()
        logger.info("ðŸš€ === DÃ‰MARRAGE DU PIPELINE MODULAIRE ===")
    
    def end_pipeline(self):
        """Termine le pipeline et calcule la durÃ©e"""
        self.end_time = time.time()
        duration = self.end_time - self.start_time if self.start_time else 0
        logger.info(f"â±ï¸ DurÃ©e totale: {duration:.2f} secondes")
        return duration
    
    def get_pipeline_status(self) -> Dict[str, Any]:
        """Retourne le statut actuel du pipeline"""
        return {
            "start_time": self.start_time,
            "end_time": self.end_time,
            "duration": (self.end_time - self.start_time) if self.start_time and self.end_time else 0,
            "orchestrator_ready": hasattr(self, 'orchestrator') and self.orchestrator is not None,
            "external_modules": {
                "similarity_detector": self.similarity_detector is not None,
                "quality_validator": self.quality_validator is not None,
                "exporter": self.exporter is not None,
                "performance_optimizer": self.performance_optimizer is not None,
                "property_normalizer": self.property_normalizer is not None,
                "validation_dashboard": self.validation_dashboard is not None
            }
        }
