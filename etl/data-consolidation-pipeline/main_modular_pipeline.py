#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üöÄ PIPELINE ETL MODULAIRE - Point d'entr√©e principal
=====================================================

Pipeline ETL modulaire pour la consolidation de donn√©es immobili√®res
Utilise une architecture modulaire pour une meilleure maintenabilit√©
"""

import sys
import logging
import time
from typing import Dict, Any

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# Import des modules modulaires
try:
    from core import (
        PipelineManager, DataProcessor, ExportManager, 
        ReportGenerator, ConfigManager
    )
except ImportError as e:
    logger.error(f"‚ùå Erreur import modules: {e}")
    sys.exit(1)

class ModularPipeline:
    """
    Pipeline ETL modulaire principal
    
    Orchestre tous les composants modulaires pour offrir
    une exp√©rience compl√®te et maintenable
    """
    
    def __init__(self):
        """Initialise le pipeline modulaire"""
        self.pipeline_manager = None
        self.data_processor = None
        self.export_manager = None
        self.report_generator = None
        self.config_manager = None
        
        logger.info("üöÄ === INITIALISATION PIPELINE MODULAIRE ===")
    
    def initialize_pipeline(self, config: Dict[str, Any]):
        """
        Initialise tous les composants du pipeline
        
        Args:
            config: Configuration du pipeline
        """
        try:
            # === GESTIONNAIRE DE PIPELINE ===
            self.pipeline_manager = PipelineManager(config)
            logger.info("‚úÖ PipelineManager initialis√©")
            
            # === PROCESSEUR DE DONN√âES ===
            self.data_processor = DataProcessor(self.pipeline_manager)
            logger.info("‚úÖ DataProcessor initialis√©")
            
            # === GESTIONNAIRE D'EXPORT ===
            self.export_manager = ExportManager(self.pipeline_manager)
            logger.info("‚úÖ ExportManager initialis√©")
            
            # === G√âN√âRATEUR DE RAPPORTS ===
            self.report_generator = ReportGenerator(self.pipeline_manager)
            logger.info("‚úÖ ReportGenerator initialis√©")
            
            logger.info("‚úÖ Tous les composants initialis√©s avec succ√®s")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation pipeline: {e}")
            raise
    
    def run_pipeline(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ex√©cute le pipeline complet
        
        Args:
            config: Configuration du pipeline
            
        Returns:
            Dict avec les r√©sultats du pipeline
        """
        try:
            # === D√âMARRAGE ===
            self.pipeline_manager.start_pipeline()
            
            # === EXTRACTION ===
            source_config = self.config_manager.get_source_config()
            df_initial = self.data_processor.extract_data(**source_config)
            
            if df_initial is None or df_initial.empty:
                logger.error("‚ùå Aucune donn√©e extraite")
                return {"status": "error", "message": "Aucune donn√©e extraite"}
            
            logger.info(f"‚úÖ Extraction r√©ussie: {df_initial.shape[0]} lignes √ó {df_initial.shape[1]} colonnes")
            
            # === VALIDATION INITIALE ===
            initial_validation = self.data_processor.validate_data(df_initial, "initial")
            
            # === MODE VALIDATION UNIQUEMENT ===
            if config.get('validate_only'):
                logger.info("üîç Mode validation uniquement - Arr√™t du pipeline")
                duration = self.pipeline_manager.end_pipeline()
                return {
                    "status": "validation_only",
                    "validation_results": initial_validation,
                    "duration_seconds": duration
                }
            
            # === D√âTECTION DE SIMILARIT√âS ===
            similarity_groups = self.data_processor.detect_similarities(df_initial)
            
            # === TRAITEMENT DES DONN√âES ===
            if not config.get('dry_run'):
                df_final = self.data_processor.process_data(df_initial, config['output'])
            else:
                logger.info("üß™ Mode dry run - Aucune transformation effectu√©e")
                df_final = df_initial.copy()
            
            # === VALIDATION FINALE ===
            final_validation = self.data_processor.validate_data(df_final, "final")
            
            # === EXPORT ===
            if not config.get('dry_run'):
                output_config = self.config_manager.get_output_config()
                exported_files = self.export_manager.export_data(
                    df_final, "modular_pipeline", 
                    output_config['formats'], output_config['output_dir']
                )
            else:
                logger.info("üß™ Mode dry run - Aucun export effectu√©")
                exported_files = {}
            
            # === G√âN√âRATION DES RAPPORTS ===
            if not config.get('dry_run'):
                reports = self.report_generator.generate_all_reports(
                    df_initial, df_final, initial_validation, final_validation,
                    similarity_groups, exported_files, config['output']
                )
            else:
                logger.info("üß™ Mode dry run - Aucun rapport g√©n√©r√©")
                reports = {}
            
            # === FINALISATION ===
            duration = self.pipeline_manager.end_pipeline()
            
            # === R√âSULTATS ===
            results = {
                "status": "success",
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "duration_seconds": duration,
                "source": config.get('source'),
                "output_directory": config.get('output'),
                "initial_shape": df_initial.shape,
                "final_shape": df_final.shape,
                "column_reduction": {
                    "initial_columns": df_initial.shape[1],
                    "final_columns": df_final.shape[1],
                    "reduction_percentage": ((df_initial.shape[1] - df_final.shape[1]) / df_initial.shape[1]) * 100
                },
                "validation_results": {
                    "initial": initial_validation,
                    "final": final_validation
                },
                "similarity_groups": similarity_groups,
                "exported_files": exported_files,
                "reports": reports
            }
            
            logger.info("üéâ === PIPELINE TERMIN√â AVEC SUCC√àS ===")
            logger.info(f"üìä R√©duction colonnes: {results['column_reduction']['reduction_percentage']:.1f}%")
            logger.info(f"üéØ Score qualit√© final: {final_validation.get('overall_score', 0):.2%}")
            
            return results
            
        except Exception as e:
            duration = self.pipeline_manager.end_pipeline() if self.pipeline_manager else 0
            logger.error(f"‚ùå Erreur dans le pipeline: {e}")
            
            return {
                "status": "error",
                "error": str(e),
                "duration_seconds": duration,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            }

def main():
    """Point d'entr√©e principal du pipeline"""
    try:
        # === INITIALISATION ===
        pipeline = ModularPipeline()
        config_manager = ConfigManager()
        
        # === PARSE DES ARGUMENTS ===
        config = config_manager.parse_arguments()
        pipeline.config_manager = config_manager
        
        # === INITIALISATION DU PIPELINE ===
        pipeline.initialize_pipeline(config)
        
        # === EX√âCUTION ===
        results = pipeline.run_pipeline(config)
        
        # === AFFICHAGE DES R√âSULTATS ===
        if results["status"] == "success":
            print(f"\nüéâ Pipeline termin√© avec succ√®s !")
            print(f"üìÅ Fichiers export√©s dans: {results['output_directory']}")
            print(f"üìã Rapports g√©n√©r√©s: {len(results['reports'])} fichiers")
            print(f"‚è±Ô∏è Dur√©e totale: {results['duration_seconds']:.2f} secondes")
        else:
            print(f"\n‚ùå Pipeline √©chou√©: {results.get('error', 'Erreur inconnue')}")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Pipeline interrompu par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
