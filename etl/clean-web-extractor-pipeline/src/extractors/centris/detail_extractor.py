"""
Extracteur de d√©tails de propri√©t√©s pour Centris.ca
Refactoris√© pour utiliser des extracteurs sp√©cialis√©s
"""

import structlog
import re
from typing import Optional
from bs4 import BeautifulSoup

from src.models.property import (
    Property, PropertyType, PropertyStatus, Address, Location, FinancialInfo, 
    PropertyFeatures, PropertyDimensions, PropertyMedia, PropertyDescription, 
    PropertyMetadata
)
from src.utils.validators import RegionValidator, PropertyValidator, DataValidator

# Import des extracteurs sp√©cialis√©s
from .extractors import AddressExtractor, FinancialExtractor, NumericExtractor

logger = structlog.get_logger()


class CentrisDetailExtractor:
    """Extracteur de d√©tails de propri√©t√©s depuis les pages de d√©tail"""
    
    def __init__(self):
        self.validators = {
            'region': RegionValidator(),
            'property': PropertyValidator(),
            'data': DataValidator()
        }
        
        # Initialisation des extracteurs sp√©cialis√©s
        self.address_extractor = AddressExtractor()
        self.financial_extractor = FinancialExtractor()
        self.numeric_extractor = NumericExtractor()
    
    async def extract_property_details(self, soup: BeautifulSoup, url: str) -> Optional[Property]:
        """
        Extrait toutes les donn√©es d'une propri√©t√© depuis sa page de d√©tail
        
        Args:
            soup: BeautifulSoup object de la page
            url: URL de la page de d√©tail
            
        Returns:
            Property: Objet Property avec tous les d√©tails ou None en cas d'√©chec
        """
        try:
            # Extraction des informations de base
            property_id = self._extract_property_id(soup)
            if not property_id:
                return None
            
            # Extraction des diff√©rentes sections avec les extracteurs sp√©cialis√©s
            address = self.address_extractor.extract_address(soup)
            financial = self.financial_extractor.extract_financial(soup)
            features = self._extract_features(soup)
            dimensions = self._extract_dimensions(soup)
            media = self._extract_media(soup)
            description = self._extract_description(soup)
            
            # Extraction des nouvelles informations d√©taill√©es
            property_usage = self._extract_property_usage(soup)
            building_style = self._extract_building_style(soup)
            parking_info = self._extract_parking_info(soup)
            units_info = self._extract_units_info(soup)
            main_unit_info = self._extract_main_unit_info(soup)
            move_in_date = self._extract_move_in_date(soup)
            walk_score = self._extract_walk_score(soup)
            
            # Extraction du type HTML exact depuis la page (ex: "Triplex")
            html_type = self._extract_html_property_type(soup)
            
            # D√©tection de la cat√©gorie depuis l'URL (ex: "Plex")
            original_url = f"https://www.centris.ca/fr/triplex~a-vendre~chambly/{property_id}"
            property_category = self._detect_property_type(original_url)
            
            # Extraction des coordonn√©es GPS
            location = self._extract_location(soup)
            
            # Cr√©ation de l'objet Property avec la nouvelle logique
            property_data = Property(
                id=property_id,
                type=html_type,  # Type: "Triplex" (depuis le HTML)
                category=property_category,  # Cat√©gorie: Plex (enum)
                status=PropertyStatus.FOR_SALE,
                address=address,
                location=location,
                financial=financial,
                features=features,
                dimensions=dimensions,
                media=media,
                description=description,
                # Nouvelles informations d√©taill√©es
                property_usage=property_usage,
                building_style=building_style,
                parking_info=parking_info,
                units_info=units_info,
                main_unit_info=main_unit_info,
                move_in_date=move_in_date,
                walk_score=walk_score,
                metadata=PropertyMetadata(
                    source="Centris",
                    source_id=property_id,
                    url=url
                )
            )
            
            # Log des types extraits
            if html_type:
                logger.info(f"üè∑Ô∏è Type HTML extrait: {html_type} (ex: Triplex)")
                logger.info(f"üè† Cat√©gorie d√©tect√©e: {property_category} (ex: Plex)")
                logger.info(f"üìä R√©sum√©: {html_type} de cat√©gorie {property_category}")
                
                # Stocker la cat√©gorie dans les m√©tadonn√©es
                if not hasattr(property_data.metadata, 'category'):
                    property_data.metadata.__dict__['category'] = str(property_category)
                    logger.info(f"üè† Cat√©gorie ajout√©e aux m√©tadonn√©es: {property_category}")
            
            # Validation et nettoyage des donn√©es
            validated_property = self._validate_and_clean_property(property_data)
            
            return validated_property
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'extraction des donn√©es d√©taill√©es: {str(e)}")
            return None
    
    def _detect_property_type(self, url: str) -> PropertyType:
        """D√©tecte le type de propri√©t√© depuis l'URL Centris"""
        try:
            # Format: https://www.centris.ca/fr/triplex~a-vendre~chambly/15236505
            if 'triplex' in url.lower():
                return PropertyType.PLEX
            elif 'condo' in url.lower():
                return PropertyType.SELL_CONDO
            elif 'terrain' in url.lower() or 'lot' in url.lower():
                return PropertyType.RESIDENTIAL_LOT
            else:
                return PropertyType.SINGLE_FAMILY_HOME
        except Exception:
            return PropertyType.SINGLE_FAMILY_HOME
    
    def _extract_property_id(self, soup: BeautifulSoup) -> Optional[str]:
        """Extrait l'ID de la propri√©t√© depuis la page de d√©tail"""
        try:
            # Recherche dans les meta tags (m√©thode la plus fiable)
            meta_id = soup.find('meta', {'property': 'og:url'})
            if meta_id:
                url = meta_id.get('content', '')
                # Format: https://www.centris.ca/fr/triplex~a-vendre~chambly/15236505
                if '/' in url:
                    return url.split('/')[-1]
            
            # Fallback: extraction depuis l'URL
            return "temp_id"
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction ID: {str(e)}")
            return "temp_id"
    
    def _extract_address(self, soup: BeautifulSoup) -> Address:
        """Extrait l'adresse d√©taill√©e depuis la page de d√©tail"""
        try:
            # Utilisation du s√©lecteur qui fonctionne selon notre analyse
            address_element = soup.find('div', {'class': 'address'})
            
            if address_element:
                full_address = address_element.get_text(strip=True)
                # Nettoyer l'adresse (enlever "Triplex √† vendre" au d√©but)
                if "Triplex √† vendre" in full_address:
                    full_address = full_address.replace("Triplex √† vendre", "").strip()
                
                # Parse l'adresse pour extraire les composants
                street, city, region = self._parse_address_text(full_address)
                
                return Address(
                    street=street,
                    city=city,
                    region=region,
                    postal_code=None,  # √Ä extraire si disponible
                    country="Canada",
                    full_address=full_address
                )
            
            return Address()
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'extraction de l'adresse: {str(e)}")
            return Address()
    
    def _parse_address_text(self, address_text: str) -> tuple[str, str, str]:
        """Parse le texte d'adresse pour extraire rue, ville et r√©gion"""
        try:
            # Format attendu: "2348 - 2352, Avenue Bourgogne, Chambly"
            parts = address_text.split(',')
            if len(parts) >= 3:
                street = f"{parts[0].strip()}, {parts[1].strip()}"  # Combiner num√©ro et nom de rue
                city = "Chambly"  # Ville fixe pour Chambly
                region = "Qu√©bec"  # R√©gion fixe
                return street, city, region
            elif len(parts) == 2:
                street = f"{parts[0].strip()}, {parts[1].strip()}"
                city = "Chambly"
                region = "Qu√©bec"
                return street, city, region
            elif len(parts) == 1:
                return parts[0].strip(), "Chambly", "Qu√©bec"
            else:
                return "", "Chambly", "Qu√©bec"
        except Exception:
            return "", "Chambly", "Qu√©bec"
    
    def _extract_financial(self, soup: BeautifulSoup) -> FinancialInfo:
        """Extrait les informations financi√®res depuis la page de d√©tail"""
        try:
            financial_info = {}
            
            # Extraction du prix
            price_element = soup.find('div', {'class': 'price'})
            if price_element:
                price_text = price_element.get_text(strip=True)
                price_clean = ''.join(filter(str.isdigit, price_text))
                if price_clean:
                    financial_info['price'] = float(price_clean)
                    logger.debug(f"üí∞ Prix extrait: {financial_info['price']}")
            
            # Extraction des revenus depuis la description
            desc_element = soup.find('div', {'class': 'property-description'})
            if desc_element:
                description_text = desc_element.get_text(strip=True)
                revenue = self._extract_revenue_from_description(description_text)
                if revenue:
                    financial_info['potential_gross_revenue'] = revenue
                    logger.debug(f"üí∞ Revenus extraits: {revenue}$")
            
            # Extraction des informations financi√®res d√©taill√©es
            financial_info.update(self._extract_detailed_financial(soup))
            
            return FinancialInfo(**financial_info)
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction financier: {str(e)}")
            return FinancialInfo()
    
    def _extract_detailed_financial(self, soup: BeautifulSoup) -> dict:
        """Extrait les informations financi√®res d√©taill√©es"""
        financial_details = {}
        
        try:
            # Recherche des revenus dans les carac-container
            carac_containers = soup.find_all('div', {'class': 'carac-container'})
            
            for container in carac_containers:
                title_elem = container.find('div', {'class': 'carac-title'})
                value_elem = container.find('div', {'class': 'carac-value'})
                
                if title_elem and value_elem:
                    title = title_elem.get_text(strip=True).lower()
                    value = value_elem.get_text(strip=True)
                    
                    if 'revenus bruts potentiels' in title:
                        # Format: "43 320 $"
                        revenue_match = re.search(r'([\d\s]+)\s*\$', value)
                        if revenue_match:
                            revenue_str = revenue_match.group(1).replace(' ', '')
                            try:
                                financial_details['potential_gross_revenue'] = float(revenue_str)
                            except ValueError:
                                pass
            
            # Recherche des √©valuations municipales et taxes
            financial_tables = soup.find_all('table')
            
            for table in financial_tables:
                # √âvaluation municipale
                if '√âvaluation municipale' in table.get_text():
                    financial_details.update(self._extract_municipal_evaluation(table))
                
                # Taxes
                elif 'Taxes' in table.get_text():
                    financial_details.update(self._extract_taxes(table))
            
            logger.debug(f"üí∞ Informations financi√®res d√©taill√©es: {financial_details}")
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction financier d√©taill√©: {e}")
        
        return financial_details
    
    def _extract_municipal_evaluation(self, table: BeautifulSoup) -> dict:
        """Extrait l'√©valuation municipale depuis le tableau"""
        evaluation = {}
        
        try:
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    label = cells[0].get_text(strip=True).lower()
                    value_text = cells[1].get_text(strip=True)
                    
                    # Extraire les valeurs num√©riques
                    value_match = re.search(r'([\d\s]+)\s*\$', value_text)
                    if value_match:
                        value_str = value_match.group(1).replace(' ', '')
                        try:
                            value = float(value_str)
                            
                            if 'terrain' in label:
                                evaluation['municipal_evaluation_land'] = value
                            elif 'b√¢timent' in label:
                                evaluation['municipal_evaluation_building'] = value
                            elif 'total' in label:
                                evaluation['municipal_evaluation_total'] = value
                                evaluation['municipal_evaluation_year'] = 2025  # Ann√©e fixe pour 2025
                        except ValueError:
                            pass
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction √©valuation municipale: {e}")
        
        return evaluation
    
    def _extract_taxes(self, table: BeautifulSoup) -> dict:
        """Extrait les taxes depuis le tableau"""
        taxes = {}
        
        try:
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    label = cells[0].get_text(strip=True).lower()
                    value_text = cells[1].get_text(strip=True)
                    
                    # Extraire les valeurs num√©riques
                    value_match = re.search(r'([\d\s]+)\s*\$', value_text)
                    if value_match:
                        value_str = value_match.group(1).replace(' ', '')
                        try:
                            value = float(value_str)
                            
                            if 'municipales' in label:
                                taxes['municipal_tax'] = value
                            elif 'scolaires' in label:
                                taxes['school_tax'] = value
                            elif 'total' in label:
                                taxes['total_taxes'] = value
                        except ValueError:
                            pass
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction taxes: {e}")
        
        return taxes
    
    def _extract_revenue_from_description(self, description: str) -> Optional[float]:
        """Extrait les revenus depuis la description"""
        try:
            # Recherche: "43 000 $ par ann√©e"
            revenue_match = re.search(r'(\d{1,3}(?:\s\d{3})*)\s*\$\s*par\s*ann√©e', description)
            if revenue_match:
                revenue_str = revenue_match.group(1).replace(' ', '')
                return float(revenue_str)
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction revenus: {e}")
        
        return None
    
    def _extract_features(self, soup: BeautifulSoup) -> PropertyFeatures:
        """Extrait les caract√©ristiques physiques depuis la page de d√©tail"""
        try:
            features = {}
            
            # Recherche dans la description pour extraire les caract√©ristiques
            desc_element = soup.find('div', {'class': 'property-description'})
            if desc_element:
                description_text = desc_element.get_text(strip=True)
                features.update(self._parse_features_from_description(description_text))
            
            # Recherche des caract√©ristiques dans le HTML
            features.update(self._extract_features_from_html(soup))
            
            return PropertyFeatures(**features)
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction caract√©ristiques: {str(e)}")
            return PropertyFeatures()
    
    def _parse_features_from_description(self, description: str) -> dict:
        """Parse les caract√©ristiques depuis la description textuelle"""
        features = {}
        
        try:
            # Compter les unit√©s de 5 ¬Ω et 4 ¬Ω
            five_half_count = description.count("5 ¬Ω")
            four_half_count = description.count("4 ¬Ω")
            
            if five_half_count > 0 or four_half_count > 0:
                # Calculer le total des chambres
                total_bedrooms = (five_half_count * 5) + (four_half_count * 4)
                features['total_bedrooms'] = total_bedrooms
                
                # Estimer le nombre de chambres principales
                features['bedrooms'] = max(five_half_count, four_half_count)
                
                # Estimer le nombre de salles de bain (g√©n√©ralement 1 par unit√©)
                features['bathrooms'] = five_half_count + four_half_count
                
                logger.debug(f"üè† Caract√©ristiques extraites: {five_half_count} unit√©s 5¬Ω, {four_half_count} unit√©s 4¬Ω")
        
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur parsing description: {e}")
        
        return features
    
    def _extract_features_from_html(self, soup: BeautifulSoup) -> dict:
        """Extrait les caract√©ristiques depuis les √©l√©ments HTML"""
        features = {}
        
        try:
            # Recherche des caract√©ristiques dans les conteneurs carac-container
            carac_containers = soup.find_all('div', {'class': 'carac-container'})
            
            for container in carac_containers:
                title_elem = container.find('div', {'class': 'carac-title'})
                value_elem = container.find('div', {'class': 'carac-value'})
                
                if title_elem and value_elem:
                    title = title_elem.get_text(strip=True).lower()
                    value = value_elem.get_text(strip=True)
                    
                    # Traitement des caract√©ristiques sp√©cifiques
                    if 'unit√©s r√©sidentielles' in title:
                        # Format: "1 x 4 ¬Ω, 2 x 5 ¬Ω"
                        features.update(self._parse_units_from_text(value))
                    elif 'unit√© principale' in title:
                        # Format: "5 pi√®ces, 3 chambres, 1 salle de bain"
                        features.update(self._parse_main_unit_from_text(value))
                    elif 'garage' in title:
                        # Format: "Garage (1)"
                        garage_match = re.search(r'\((\d+)\)', value)
                        if garage_match:
                            features['garages'] = int(garage_match.group(1))
            
            logger.debug(f"üè† Caract√©ristiques HTML extraites: {features}")
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction HTML: {e}")
        
        return features
    
    def _extract_property_details(self, soup: BeautifulSoup, url: str) -> Optional[Property]:
        """Extrait les d√©tails complets d'une propri√©t√© depuis sa page HTML."""
        try:
            # Extraction de l'ID de la propri√©t√©
            property_id = self._extract_property_id(soup)
            if not property_id:
                logger.error(f"‚ùå Impossible d'extraire l'ID de la propri√©t√© depuis {url}")
                return None
            
            # Extraction des informations de base
            address = self._extract_address(soup)
            financial = self._extract_financial(soup)
            description = self._extract_description(soup)
            features = self._extract_features(soup)
            dimensions = self._extract_dimensions(soup)
            media = self._extract_media(soup)
            
            # Extraction des nouvelles informations d√©taill√©es
            property_usage = self._extract_property_usage(soup)
            building_style = self._extract_building_style(soup)
            parking_info = self._extract_parking_info(soup)
            units_info = self._extract_units_info(soup)
            main_unit_info = self._extract_main_unit_info(soup)
            move_in_date = self._extract_move_in_date(soup)
            walk_score = self._extract_walk_score(soup)
            
            # Extraction du type HTML exact depuis la page (ex: "Triplex")
            html_type = self._extract_html_property_type(soup)
            
            # D√©tection de la cat√©gorie depuis l'URL (ex: "Plex")
            original_url = f"https://www.centris.ca/fr/triplex~a-vendre~chambly/{property_id}"
            property_category = self._detect_property_type(original_url)
            
            # Extraction des coordonn√©es GPS
            location = self._extract_location(soup)
            
            # Cr√©ation de l'objet Property avec la nouvelle logique
            property_data = Property(
                id=property_id,
                type=html_type,  # Type: "Triplex" (depuis le HTML)
                category=property_category,  # Cat√©gorie: Plex (enum)
                status=PropertyStatus.FOR_SALE,
                address=address,
                location=location,
                financial=financial,
                features=features,
                dimensions=dimensions,
                media=media,
                description=description,
                # Nouvelles informations d√©taill√©es
                property_usage=property_usage,
                building_style=building_style,
                parking_info=parking_info,
                units_info=units_info,
                main_unit_info=main_unit_info,
                move_in_date=move_in_date,
                walk_score=walk_score,
                metadata=PropertyMetadata(
                    source="Centris",
                    source_id=property_id,
                    url=url
                )
            )
            
            # Log des types extraits
            if html_type:
                logger.info(f"üè∑Ô∏è Type HTML extrait: {html_type} (ex: Triplex)")
                logger.info(f"üè† Cat√©gorie d√©tect√©e: {property_category} (ex: Plex)")
                logger.info(f"üìä R√©sum√©: {html_type} de cat√©gorie {property_category}")
            
            # Validation et nettoyage des donn√©es
            validated_property = self._validate_and_clean_property(property_data)
            
            if validated_property:
                logger.info(f"‚úÖ D√©tails extraits pour {validated_property.address.street}")
            else:
                logger.warning(f"‚ö†Ô∏è Propri√©t√© {property_id} non valid√©e")
            
            return validated_property
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'extraction des d√©tails: {e}")
            return None
    
    def _extract_property_usage(self, soup: BeautifulSoup) -> Optional[str]:
        """Extrait l'utilisation de la propri√©t√© (ex: R√©sidentielle)"""
        try:
            logger.debug("üîç D√©but extraction utilisation propri√©t√©")
            # Recherche plus flexible
            carac_containers = soup.find_all('div', class_='carac-container')
            logger.debug(f"üîç Trouv√© {len(carac_containers)} conteneurs carac-container")
            
            for i, container in enumerate(carac_containers):
                title_elem = container.find('div', class_='carac-title')
                if title_elem:
                    title_text = title_elem.get_text(strip=True).lower()
                    logger.debug(f"üîç Conteneur {i}: titre = '{title_text}'")
                    
                    if 'utilisation' in title_text and 'propri√©t√©' in title_text:
                        value_elem = container.find('div', class_='carac-value')
                        if value_elem:
                            value = value_elem.get_text(strip=True)
                            logger.debug(f"üè† Utilisation trouv√©e: {value}")
                            return value
                        else:
                            logger.debug(f"‚ö†Ô∏è Pas de valeur trouv√©e pour l'utilisation")
                    else:
                        logger.debug(f"üîç Titre ne correspond pas aux crit√®res")
                else:
                    logger.debug(f"‚ö†Ô∏è Pas de titre trouv√© dans le conteneur {i}")
            
            logger.debug("üîç Aucune utilisation trouv√©e")
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction utilisation propri√©t√©: {e}")
            return None
    
    def _extract_building_style(self, soup: BeautifulSoup) -> Optional[str]:
        """Extrait le style de b√¢timent (ex: Jumel√©)"""
        try:
            # Recherche plus flexible
            carac_containers = soup.find_all('div', class_='carac-container')
            for container in carac_containers:
                title_elem = container.find('div', class_='carac-title')
                if title_elem:
                    title_text = title_elem.get_text(strip=True).lower()
                    if 'style' in title_text and 'b√¢timent' in title_text:
                        value_elem = container.find('div', class_='carac-value')
                        if value_elem:
                            value = value_elem.get_text(strip=True)
                            logger.debug(f"üèóÔ∏è Style b√¢timent trouv√©: {value}")
                            return value
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction style b√¢timent: {e}")
        return None
    
    def _extract_parking_info(self, soup: BeautifulSoup) -> Optional[str]:
        """Extrait les informations de stationnement (ex: Garage (1))"""
        try:
            # Recherche plus flexible
            carac_containers = soup.find_all('div', class_='carac-container')
            for container in carac_containers:
                title_elem = container.find('div', class_='carac-title')
                if title_elem:
                    title_text = title_elem.get_text(strip=True).lower()
                    if 'stationnement' in title_text and 'total' in title_text:
                        value_elem = container.find('div', class_='carac-value')
                        if value_elem:
                            value = value_elem.get_text(strip=True)
                            logger.debug(f"üöó Stationnement trouv√©: {value}")
                            return value
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction stationnement: {e}")
        return None
    
    def _extract_units_info(self, soup: BeautifulSoup) -> Optional[str]:
        """Extrait le nombre d'unit√©s (ex: R√©sidentiel (3))"""
        try:
            logger.debug("üîç D√©but extraction nombre d'unit√©s")
            # Recherche plus flexible
            carac_containers = soup.find_all('div', class_='carac-container')
            
            for i, container in enumerate(carac_containers):
                title_elem = container.find('div', class_='carac-title')
                if title_elem:
                    title_text = title_elem.get_text(strip=True).lower()
                    logger.debug(f"üîç Conteneur {i}: titre = '{title_text}'")
                    
                    if 'nombre' in title_text and 'unit√©s' in title_text:
                        value_elem = container.find('div', class_='carac-value')
                        if value_elem:
                            value = value_elem.get_text(strip=True)
                            logger.debug(f"üèòÔ∏è Nombre d'unit√©s trouv√©: {value}")
                            return value
                        else:
                            logger.debug(f"‚ö†Ô∏è Pas de valeur trouv√©e pour le nombre d'unit√©s")
                    else:
                        logger.debug(f"üîç Titre ne correspond pas aux crit√®res")
                else:
                    logger.debug(f"‚ö†Ô∏è Pas de titre trouv√© dans le conteneur {i}")
            
            logger.debug("üîç Aucun nombre d'unit√©s trouv√©")
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction nombre d'unit√©s: {e}")
            return None
    
    def _extract_main_unit_info(self, soup: BeautifulSoup) -> Optional[str]:
        """Extrait les informations de l'unit√© principale (ex: 5 pi√®ces, 3 chambres, 1 salle de bain)"""
        try:
            logger.debug("üîç D√©but extraction unit√© principale")
            # Recherche plus flexible
            carac_containers = soup.find_all('div', class_='carac-container')
            
            for i, container in enumerate(carac_containers):
                title_elem = container.find('div', class_='carac-title')
                if title_elem:
                    title_text = title_elem.get_text(strip=True).lower()
                    logger.debug(f"üîç Conteneur {i}: titre = '{title_text}'")
                    
                    if 'unit√©' in title_text and 'principale' in title_text:
                        value_elem = container.find('div', class_='carac-value')
                        if value_elem:
                            value = value_elem.get_text(strip=True)
                            logger.debug(f"üè† Unit√© principale trouv√©e: {value}")
                            return value
                        else:
                            logger.debug(f"‚ö†Ô∏è Pas de valeur trouv√©e pour l'unit√© principale")
                    else:
                        logger.debug(f"üîç Titre ne correspond pas aux crit√®res")
                else:
                    logger.debug(f"‚ö†Ô∏è Pas de titre trouv√© dans le conteneur {i}")
            
            logger.debug("üîç Aucune unit√© principale trouv√©e")
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction unit√© principale: {e}")
            return None
    
    def _extract_move_in_date(self, soup: BeautifulSoup) -> Optional[str]:
        """Extrait la date d'emm√©nagement (ex: Selon les baux)"""
        try:
            logger.debug("üîç D√©but extraction date d'emm√©nagement")
            # Recherche plus flexible
            carac_containers = soup.find_all('div', class_='carac-container')
            
            for i, container in enumerate(carac_containers):
                title_elem = container.find('div', class_='carac-title')
                if title_elem:
                    title_text = title_elem.get_text(strip=True).lower()
                    logger.debug(f"üîç Conteneur {i}: titre = '{title_text}'")
                    
                    if 'date' in title_text and 'emm√©nagement' in title_text:
                        value_elem = container.find('div', class_='carac-value')
                        if value_elem:
                            value = value_elem.get_text(strip=True)
                            logger.debug(f"üìÖ Date d'emm√©nagement trouv√©e: {value}")
                            return value
                        else:
                            logger.debug(f"‚ö†Ô∏è Pas de valeur trouv√©e pour la date d'emm√©nagement")
                    else:
                        logger.debug(f"üîç Titre ne correspond pas aux crit√®res")
                else:
                    logger.debug(f"‚ö†Ô∏è Pas de titre trouv√© dans le conteneur {i}")
            
            logger.debug("üîç Aucune date d'emm√©nagement trouv√©e")
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction date d'emm√©nagement: {e}")
            return None
    
    def _extract_walk_score(self, soup: BeautifulSoup) -> Optional[int]:
        """Extrait le Walk Score depuis le HTML"""
        try:
            logger.debug("üîç D√©but extraction Walk Score")
            walkscore_elem = soup.find('div', class_='walkscore')
            if walkscore_elem:
                score_elem = walkscore_elem.find('span')
                if score_elem:
                    score_text = score_elem.get_text(strip=True)
                    try:
                        score = int(score_text)
                        logger.debug(f"üö∂ Walk Score trouv√©: {score}")
                        return score
                    except ValueError:
                        logger.debug(f"‚ö†Ô∏è Walk Score non num√©rique: {score_text}")
            logger.debug("üîç Aucun Walk Score trouv√©")
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction Walk Score: {e}")
            return None

    def _validate_and_clean_property(self, property_data: Property) -> Property:
        """
        Valide et nettoie les donn√©es d'une propri√©t√©
        
        Args:
            property_data: Propri√©t√© √† valider
            
        Returns:
            Property: Propri√©t√© valid√©e et nettoy√©e
        """
        try:
            # Validation et nettoyage de l'adresse
            if property_data.address:
                # Validation de la r√©gion
                if property_data.address.region:
                    if not self.validators['region'].is_valid_region(property_data.address.region):
                        logger.warning(f"‚ö†Ô∏è R√©gion invalide d√©tect√©e: {property_data.address.region}")
                        # Essayer de normaliser la r√©gion
                        normalized_region = self.validators['region'].normalize_region(property_data.address.region)
                        if normalized_region:
                            property_data.address.region = normalized_region
                            logger.info(f"‚úÖ R√©gion normalis√©e: {property_data.address.region}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Impossible de normaliser la r√©gion: {property_data.address.region}")
                
                # Validation du code postal
                if property_data.address.postal_code:
                    if not self.validators['property'].is_valid_postal_code(property_data.address.postal_code):
                        logger.warning(f"‚ö†Ô∏è Code postal invalide: {property_data.address.postal_code}")
                
                # Nettoyage des textes d'adresse
                if property_data.address.street:
                    property_data.address.street = self.validators['data'].clean_text(property_data.address.street)
                if property_data.address.city:
                    property_data.address.city = self.validators['data'].clean_text(property_data.address.city)
            
            # Validation des informations financi√®res
            if property_data.financial and property_data.financial.price:
                if not self.validators['property'].is_valid_price(property_data.financial.price):
                    logger.warning(f"‚ö†Ô∏è Prix invalide d√©tect√©: {property_data.financial.price}")
            
            # Validation des coordonn√©es g√©ographiques
            if (property_data.address and 
                hasattr(property_data.address, 'latitude') and 
                hasattr(property_data.address, 'longitude')):
                
                if not self.validators['data'].is_valid_coordinates(
                    property_data.address.latitude, 
                    property_data.address.longitude
                ):
                    logger.warning(f"‚ö†Ô∏è Coordonn√©es g√©ographiques invalides: {property_data.address.latitude}, {property_data.address.longitude}")
            
            # Validation de l'ID
            if not self.validators['property'].is_valid_property_id(property_data.id):
                logger.warning(f"‚ö†Ô∏è ID de propri√©t√© invalide: {property_data.id}")
            
            logger.debug(f"‚úÖ Propri√©t√© {property_data.id} valid√©e et nettoy√©e")
            return property_data
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la validation: {str(e)}")
            return property_data

    def _extract_numeric_values(self, soup: BeautifulSoup) -> dict:
        """Extrait les valeurs num√©riques sp√©cifiques du HTML"""
        numeric_values = {}
        
        try:
            logger.debug("üîç D√©but extraction valeurs num√©riques")
            carac_containers = soup.find_all('div', class_='carac-container')
            
            for container in carac_containers:
                title_elem = container.find('div', class_='carac-title')
                value_elem = container.find('div', class_='carac-value')
                
                if title_elem and value_elem:
                    title = title_elem.get_text(strip=True).lower()
                    value = value_elem.get_text(strip=True)
                    
                    # Ann√©e de construction
                    if 'ann√©e de construction' in title:
                        try:
                            year = int(value)
                            numeric_values['construction_year'] = year
                            logger.debug(f"üèóÔ∏è Ann√©e construction: {year}")
                        except ValueError:
                            logger.debug(f"‚ö†Ô∏è Ann√©e non num√©rique: {value}")
                    
                    # Superficie du terrain
                    elif 'superficie du terrain' in title:
                        # Format: "5 654 pc" -> 5654
                        area_match = re.search(r'(\d+(?:\s+\d+)*)', value)
                        if area_match:
                            area_text = area_match.group(1).replace(' ', '')
                            try:
                                area = int(area_text)
                                numeric_values['terrain_area'] = area
                                logger.debug(f"üìè Superficie terrain: {area} pc")
                            except ValueError:
                                logger.debug(f"‚ö†Ô∏è Superficie non num√©rique: {area_text}")
                    
                    # Stationnement total
                    elif 'stationnement total' in title:
                        # Format: "Garage (1)" -> 1
                        parking_match = re.search(r'\((\d+)\)', value)
                        if parking_match:
                            parking_count = int(parking_match.group(1))
                            numeric_values['parking_count'] = parking_count
                            logger.debug(f"üöó Nombre stationnements: {parking_count}")
                    
                    # Nombre d'unit√©s
                    elif 'nombre d\'unit√©s' in title:
                        # Format: "R√©sidentiel (3)" -> 3
                        units_match = re.search(r'\((\d+)\)', value)
                        if units_match:
                            units_count = int(units_match.group(1))
                            numeric_values['units_count'] = units_count
                            logger.debug(f"üèòÔ∏è Nombre d'unit√©s: {units_count}")
                    
                    # Revenus bruts potentiels
                    elif 'revenus bruts potentiels' in title:
                        # Format: "43 320 $" -> 43320
                        revenue_match = re.search(r'(\d+(?:\s+\d+)*)', value)
                        if revenue_match:
                            revenue_text = revenue_match.group(1).replace(' ', '')
                            try:
                                revenue = int(revenue_text)
                                numeric_values['potential_revenue'] = revenue
                                logger.debug(f"üí∞ Revenus potentiels: {revenue}$")
                            except ValueError:
                                logger.debug(f"‚ö†Ô∏è Revenus non num√©riques: {revenue_text}")
            
            logger.debug(f"üî¢ Valeurs num√©riques extraites: {numeric_values}")
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction valeurs num√©riques: {e}")
        
        return numeric_values

    def _extract_detailed_features(self, soup: BeautifulSoup) -> dict:
        """Extrait les caract√©ristiques d√©taill√©es avec valeurs num√©riques"""
        detailed_features = {}
        
        try:
            logger.debug("üîç D√©but extraction caract√©ristiques d√©taill√©es")
            carac_containers = soup.find_all('div', class_='carac-container')
            
            for container in carac_containers:
                title_elem = container.find('div', class_='carac-title')
                value_elem = container.find('div', class_='carac-value')
                
                if title_elem and value_elem:
                    title = title_elem.get_text(strip=True).lower()
                    value = value_elem.get_text(strip=True)
                    
                    # Unit√©s r√©sidentielles d√©taill√©es
                    if 'unit√©s r√©sidentielles' in title:
                        # Format: "1 x 4 ¬Ω, 2 x 5 ¬Ω"
                        detailed_features['residential_units_detail'] = value
                        logger.debug(f"üè† Unit√©s r√©sidentielles: {value}")
                        
                        # Extraction des nombres
                        units_pattern = r'(\d+)\s*x\s*(\d+(?:¬Ω)?)'
                        units_matches = re.findall(units_pattern, value)
                        if units_matches:
                            detailed_features['units_breakdown'] = units_matches
                            logger.debug(f"üî¢ D√©tail unit√©s: {units_matches}")
                    
                    # Unit√© principale d√©taill√©e
                    elif 'unit√© principale' in title:
                        # Format: "5 pi√®ces, 3 chambres, 1 salle de bain"
                        detailed_features['main_unit_detail'] = value
                        logger.debug(f"üè† Unit√© principale: {value}")
                        
                        # Extraction des nombres
                        numbers = re.findall(r'(\d+)', value)
                        if numbers:
                            detailed_features['main_unit_numbers'] = [int(n) for n in numbers]
                            logger.debug(f"üî¢ Nombres unit√© principale: {numbers}")
            
            logger.debug(f"üîç Caract√©ristiques d√©taill√©es: {detailed_features}")
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction caract√©ristiques d√©taill√©es: {e}")
        
        return detailed_features
    
    def _parse_units_from_text(self, text: str) -> dict:
        """Parse le texte des unit√©s r√©sidentielles"""
        features = {}
        
        try:
            # Format: "1 x 4 ¬Ω, 2 x 5 ¬Ω"
            
            # Compter les unit√©s de 4 ¬Ω
            four_half_match = re.search(r'(\d+)\s*x\s*4\s*¬Ω', text)
            if four_half_match:
                four_half_count = int(four_half_match.group(1))
                features['bedrooms_basement'] = four_half_count * 4
            
            # Compter les unit√©s de 5 ¬Ω
            five_half_match = re.search(r'(\d+)\s*x\s*5\s*¬Ω', text)
            if five_half_match:
                five_half_count = int(five_half_match.group(1))
                features['bedrooms'] = five_half_count * 5
            
            # Total des chambres
            if 'bedrooms' in features or 'bedrooms_basement' in features:
                total = (features.get('bedrooms', 0) + features.get('bedrooms_basement', 0))
                features['total_bedrooms'] = total
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur parsing unit√©s: {e}")
        
        return features
    
    def _parse_main_unit_from_text(self, text: str) -> dict:
        """Parse le texte de l'unit√© principale"""
        features = {}
        
        try:
            # Format: "5 pi√®ces, 3 chambres, 1 salle de bain"
            
            # Pi√®ces
            pieces_match = re.search(r'(\d+)\s*pi√®ces', text)
            if pieces_match:
                features['rooms'] = int(pieces_match.group(1))
            
            # Chambres
            chambres_match = re.search(r'(\d+)\s*chambres', text)
            if chambres_match:
                features['bedrooms'] = int(chambres_match.group(1))
            
            # Salles de bain
            sdb_match = re.search(r'(\d+)\s*salle\s*de\s*bain', text)
            if sdb_match:
                features['bathrooms'] = int(sdb_match.group(1))
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur parsing unit√© principale: {e}")
        
        return features
    
    def _extract_dimensions(self, soup: BeautifulSoup) -> PropertyDimensions:
        """Extrait les dimensions depuis la page de d√©tail"""
        try:
            dimensions = {}
            
            # Recherche des dimensions dans les conteneurs carac-container
            carac_containers = soup.find_all('div', {'class': 'carac-container'})
            
            for container in carac_containers:
                title_elem = container.find('div', {'class': 'carac-title'})
                value_elem = container.find('div', {'class': 'carac-value'})
                
                if title_elem and value_elem:
                    title = title_elem.get_text(strip=True).lower()
                    value = value_elem.get_text(strip=True)
                    
                    # Traitement des dimensions sp√©cifiques
                    if 'ann√©e de construction' in title:
                        # Format: "1976"
                        try:
                            dimensions['year_built'] = int(value)
                        except ValueError:
                            pass
                    elif 'superficie du terrain' in title:
                        # Format: "5 654 pc"
                        area_match = re.search(r'([\d\s]+)\s*pc', value)
                        if area_match:
                            area_str = area_match.group(1).replace(' ', '')
                            try:
                                dimensions['lot_size'] = float(area_str)
                            except ValueError:
                                pass
            
            logger.debug(f"üìè Dimensions extraites: {dimensions}")
            
            return PropertyDimensions(**dimensions)
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction dimensions: {str(e)}")
            return PropertyDimensions()
    
    def _extract_media(self, soup: BeautifulSoup) -> PropertyMedia:
        """Extrait les m√©dias depuis la page de d√©tail"""
        try:
            images = []
            main_image = None
            
            # 1. Extraction depuis le JavaScript MosaicPhotoUrls (m√©thode principale)
            script_tags = soup.find_all('script')
            for script in script_tags:
                script_text = script.get_text()
                if 'MosaicPhotoUrls' in script_text:
                    # Recherche du pattern: window.MosaicPhotoUrls = ["url1", "url2", ...]
                    urls_match = re.search(r'window\.MosaicPhotoUrls\s*=\s*\[(.*?)\]', script_text, re.DOTALL)
                    if urls_match:
                        urls_text = urls_match.group(1)
                        # Extraire les URLs entre guillemets
                        urls = re.findall(r'"([^"]+)"', urls_text)
                        images.extend(urls)
                        logger.debug(f"üñºÔ∏è {len(urls)} images trouv√©es dans MosaicPhotoUrls")
                        break
            
            # 2. Fallback: recherche des images avec diff√©rents s√©lecteurs
            if not images:
                img_selectors = [
                    'img[src*="centris"]',
                    '.property-image',
                    '.main-image',
                    '.hero-image',
                    '.gallery img'
                ]
                
                for selector in img_selectors:
                    img_elements = soup.select(selector)
                    for img in img_elements:
                        src = img.get('src')
                        if src and src not in images:
                            # Filtrer les images non-propri√©t√© (logos, etc.)
                            if 'property' in src.lower() or 'listing' in src.lower() or 'photo' in src.lower():
                                images.append(src)
                                if not main_image:
                                    main_image = src
            
            # 3. D√©finir l'image principale
            if not main_image and images:
                main_image = images[0]
            
            # 4. Filtrer les images valides
            valid_images = []
            for img in images:
                if img.startswith('http') and 'centris.ca' in img:
                    valid_images.append(img)
            
            logger.debug(f"üñºÔ∏è {len(valid_images)} images valides extraites")
            
            return PropertyMedia(
                main_image=main_image,
                images=valid_images,
                image_count=len(valid_images)
            )
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction m√©dias: {str(e)}")
            return PropertyMedia()
    
    def _extract_description(self, soup: BeautifulSoup) -> PropertyDescription:
        """Extrait les descriptions depuis la page de d√©tail"""
        try:
            # Utilisation du s√©lecteur qui fonctionne selon notre analyse
            desc_element = soup.find('div', {'class': 'property-description'})
            
            description = ""
            if desc_element:
                description = desc_element.get_text(strip=True)
                # Nettoyer la description
                description = self._clean_description(description)
                logger.debug(f"üìù Description extraite et nettoy√©e: {description[:100]}...")
            
            return PropertyDescription(short_description=description, long_description=description)
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction description: {str(e)}")
            return PropertyDescription()
    
    def _clean_description(self, description: str) -> str:
        """Nettoie la description des artefacts"""
        try:
            # Enlever "Description" au d√©but
            if description.startswith("Description"):
                description = description[11:].strip()
            
            # Enlever les artefacts "No Centris{ID}"
            description = re.sub(r'No Centris\d+', '', description)
            
            # Nettoyer les espaces multiples
            description = ' '.join(description.split())
            
            return description
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur nettoyage description: {e}")
            return description
    
    def _extract_location(self, soup: BeautifulSoup) -> Location:
        """Extrait les coordonn√©es g√©ographiques depuis la page de d√©tail"""
        try:
            location = {}
            
            # 1. Recherche des coordonn√©es dans les meta tags
            meta_lat = soup.find('meta', {'itemprop': 'latitude'})
            meta_lng = soup.find('meta', {'itemprop': 'longitude'})
            
            if meta_lat and meta_lng:
                try:
                    lat = float(meta_lat.get('content', ''))
                    lng = float(meta_lng.get('content', ''))
                    location['latitude'] = lat
                    location['longitude'] = lng
                    logger.debug(f"üìç Coordonn√©es GPS extraites: {lat}, {lng}")
                except ValueError:
                    pass
            
            # 2. Fallback: recherche dans les spans cach√©s
            if not location:
                lat_span = soup.find('span', {'id': 'PropertyLat'})
                lng_span = soup.find('span', {'id': 'PropertyLng'})
                
                if lat_span and lng_span:
                    try:
                        lat = float(lat_span.get_text(strip=True))
                        lng = float(lng_span.get_text(strip=True))
                        location['latitude'] = lat
                        location['longitude'] = lng
                        logger.debug(f"üìç Coordonn√©es GPS extraites (fallback): {lat}, {lng}")
                    except ValueError:
                        pass
            
            return Location(**location)
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction localisation: {str(e)}")
            return Location()
    
    def _extract_html_property_type(self, soup: BeautifulSoup) -> Optional[str]:
        """Extrait le type exact de propri√©t√© depuis le HTML de la page"""
        try:
            # 1. Recherche dans le titre principal (PageTitle)
            page_title = soup.find('span', {'data-id': 'PageTitle'})
            if page_title:
                title_text = page_title.get_text(strip=True)
                # Extraire le type avant "√† vendre"
                if '√† vendre' in title_text:
                    html_type = title_text.split('√† vendre')[0].strip()
                    logger.debug(f"üè∑Ô∏è Type HTML trouv√© dans PageTitle: {html_type}")
                    return html_type
            
            # 2. Recherche dans les meta tags
            meta_name = soup.find('meta', {'itemprop': 'name'})
            if meta_name:
                meta_content = meta_name.get('content', '')
                # Format: "Triplex √† vendre √† Chambly, Mont√©r√©gie, ..."
                if '√† vendre' in meta_content:
                    html_type = meta_content.split('√† vendre')[0].strip()
                    logger.debug(f"üè∑Ô∏è Type HTML trouv√© dans meta name: {html_type}")
                    return html_type
            
            # 3. Recherche dans le titre H1
            h1_title = soup.find('h1', {'itemprop': 'category'})
            if h1_title:
                h1_text = h1_title.get_text(strip=True)
                if '√† vendre' in h1_text:
                    html_type = h1_text.split('√† vendre')[0].strip()
                    logger.debug(f"üè∑Ô∏è Type HTML trouv√© dans H1: {html_type}")
                    return html_type
            
            logger.debug("‚ö†Ô∏è Aucun type HTML trouv√© dans la page")
            return None
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è Erreur extraction type HTML: {str(e)}")
            return None
    
    def _validate_and_clean_property(self, property_data: Property) -> Property:
        """
        Valide et nettoie les donn√©es d'une propri√©t√©
        
        Args:
            property_data: Propri√©t√© √† valider
            
        Returns:
            Property: Propri√©t√© valid√©e et nettoy√©e
        """
        try:
            # Validation et nettoyage de l'adresse
            if property_data.address:
                # Validation de la r√©gion
                if property_data.address.region:
                    if not self.validators['region'].is_valid_region(property_data.address.region):
                        logger.warning(f"‚ö†Ô∏è R√©gion invalide d√©tect√©e: {property_data.address.region}")
                        # Essayer de normaliser la r√©gion
                        normalized_region = self.validators['region'].normalize_region(property_data.address.region)
                        if normalized_region:
                            property_data.address.region = normalized_region
                            logger.info(f"‚úÖ R√©gion normalis√©e: {property_data.address.region}")
                        else:
                            logger.warning(f"‚ö†Ô∏è Impossible de normaliser la r√©gion: {property_data.address.region}")
                
                # Validation du code postal
                if property_data.address.postal_code:
                    if not self.validators['property'].is_valid_postal_code(property_data.address.postal_code):
                        logger.warning(f"‚ö†Ô∏è Code postal invalide: {property_data.address.postal_code}")
                
                # Nettoyage des textes d'adresse
                if property_data.address.street:
                    property_data.address.street = self.validators['data'].clean_text(property_data.address.street)
                if property_data.address.city:
                    property_data.address.city = self.validators['data'].clean_text(property_data.address.city)
            
            # Validation des informations financi√®res
            if property_data.financial and property_data.financial.price:
                if not self.validators['property'].is_valid_price(property_data.financial.price):
                    logger.warning(f"‚ö†Ô∏è Prix invalide d√©tect√©: {property_data.financial.price}")
            
            # Validation des coordonn√©es g√©ographiques
            if (property_data.address and 
                hasattr(property_data.address, 'latitude') and 
                hasattr(property_data.address, 'longitude')):
                
                if not self.validators['data'].is_valid_coordinates(
                    property_data.address.latitude, 
                    property_data.address.longitude
                ):
                    logger.warning(f"‚ö†Ô∏è Coordonn√©es g√©ographiques invalides: {property_data.address.latitude}, {property_data.address.longitude}")
            
            # Validation de l'ID
            if not self.validators['property'].is_valid_property_id(property_data.id):
                logger.warning(f"‚ö†Ô∏è ID de propri√©t√© invalide: {property_data.id}")
            
            logger.debug(f"‚úÖ Propri√©t√© {property_data.id} valid√©e et nettoy√©e")
            return property_data
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la validation: {str(e)}")
            return property_data

