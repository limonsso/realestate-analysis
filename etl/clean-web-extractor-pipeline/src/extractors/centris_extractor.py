"""
Extracteur Centris Modulaire - Point d'entr√©e principal
"""

from typing import List, Optional, Dict, Any
import structlog
from bs4 import BeautifulSoup

from src.models.property import SearchQuery, PropertySummary, Property
from .centris.session_manager import CentrisSessionManager
from .centris.search_manager import CentrisSearchManager
from .centris.summary_extractor import CentrisSummaryExtractor
from .centris.detail_extractor_refactored import CentrisDetailExtractor
from .centris.data_validator import CentrisDataValidator

logger = structlog.get_logger()


class CentrisExtractor:
    """
    Extracteur principal pour Centris.ca utilisant une architecture modulaire.
    
    Cette classe orchestre les diff√©rents composants sp√©cialis√©s :
    - SessionManager : Gestion des sessions HTTP
    - SearchManager : Gestion des requ√™tes de recherche
    - SummaryExtractor : Extraction des r√©sum√©s de propri√©t√©s
    - DetailExtractor : Extraction des d√©tails complets
    - DataValidator : Validation des donn√©es extraites
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        Initialise l'extracteur avec sa configuration.
        
        Args:
            config: Configuration pour l'extraction Centris
        """
        self.config = config
        self.session_manager = CentrisSessionManager(config)
        self.search_manager = CentrisSearchManager(self.session_manager, config)
        self.summary_extractor = CentrisSummaryExtractor(self.session_manager)
        self.detail_extractor = CentrisDetailExtractor(config=config)
        self.data_validator = CentrisDataValidator()
        
        logger.info("üîß CentrisExtractor initialis√© avec architecture modulaire")
        logger.info(f"üîí Configuration utilis√©e: {self.config}")
    
    async def extract_summaries(self, search_query: SearchQuery) -> List[PropertySummary]:
        """
        Extrait les r√©sum√©s de propri√©t√©s pour une requ√™te donn√©e.
        
        Args:
            search_query: Requ√™te de recherche
            
        Returns:
            List[PropertySummary]: Liste des r√©sum√©s extraits
        """
        try:
            logger.info(f"üîç Extraction des r√©sum√©s pour {search_query.locations} - {search_query.property_types}")
            
            # Recherche pagin√©e avec le SearchManager
            search_results = await self.search_manager.search_with_pagination(search_query)
            
            # Extraction des r√©sum√©s avec le SummaryExtractor
            summaries = []
            for page_content in search_results:
                page_summaries = self.summary_extractor.extract_summaries_from_html(page_content)
                summaries.extend(page_summaries)
            
            # Validation des r√©sum√©s
            validation_success = self.data_validator.validate_search_results(summaries, search_query)
            
            if validation_success:
                logger.info(f"üéâ Extraction termin√©e: {len(summaries)} propri√©t√©s trouv√©es au total")
            else:
                logger.warning(f"‚ö†Ô∏è Validation √©chou√©e mais {len(summaries)} propri√©t√©s extraites")
            
            return summaries
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'extraction des r√©sum√©s: {e}")
            raise
    
    async def extract_details(self, property_url: str) -> Optional[Property]:
        """
        Extrait les d√©tails complets d'une propri√©t√©.
        
        Args:
            property_url: URL de la propri√©t√©
            
        Returns:
            Optional[Property]: Propri√©t√© avec d√©tails complets ou None
        """
        try:
            # R√©cup√©rer le contenu HTML de la page
            async with self.session_manager.session.get(property_url) as response:
                if response.status != 200:
                    logger.error(f"‚ùå Erreur HTTP {response.status} pour {property_url}")
                    return None
                
                html_content = await response.text()
                soup = BeautifulSoup(html_content, 'html.parser')
                
                # Appeler l'extracteur avec soup et URL
                return await self.detail_extractor.extract_property_details(soup, property_url)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'extraction des d√©tails: {e}")
            return None
    
    async def extract_property_batch(self, urls: List[str]) -> List[Property]:
        """
        Extrait les d√©tails d'un lot de propri√©t√©s en parall√®le.
        
        Args:
            urls: Liste des URLs de propri√©t√©s
            
        Returns:
            List[Property]: Liste des propri√©t√©s extraites
        """
        return await self.detail_extractor.extract_properties_batch(urls)
    
    async def close(self):
        """Ferme les ressources de l'extracteur."""
        try:
            await self.session_manager.close()
            logger.info("üîå CentrisExtractor ferm√© proprement")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erreur lors de la fermeture: {e}")
