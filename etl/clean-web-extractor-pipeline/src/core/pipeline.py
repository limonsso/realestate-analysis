"""
Pipeline principal d'extraction web immobili√®re
Syst√®me d'ex√©cution autonome sans d√©pendances externes
"""

import asyncio
import argparse
import sys
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from pathlib import Path
import signal

from config.settings import config
from src.models.property import Property, PropertySummary, SearchQuery, PropertyType
from src.extractors.centris_extractor import CentrisExtractor
from src.services.database_service import DatabaseService
from src.utils.logging import setup_logging, LogContext, get_logger


class PipelineExecutor:
    """Ex√©cuteur de pipeline autonome avec gestion des param√®tres"""
    
    def __init__(self, args):
        self.args = args
        self.logger = get_logger()
        self.db_service = None
        self.running = True
        
        # Configuration des signaux pour arr√™t propre
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """Gestionnaire de signaux pour arr√™t propre"""
        self.logger.info(f"üì° Signal re√ßu: {signum}, arr√™t en cours...")
        self.running = False
    
    async def setup_database(self) -> DatabaseService:
        """Configure et initialise la base de donn√©es"""
        self.logger.info("üîß Configuration de la base de donn√©es...")
        
        try:
            # Application des param√®tres de ligne de commande
            db_config = config.database.copy()
            
            if self.args.database_name:
                db_config.database_name = self.args.database_name
                self.logger.info(f"üìä Utilisation de la base de donn√©es: {db_config.database_name}")
            
            if self.args.table_name:
                # Remplace la configuration par d√©faut
                db_config.properties_collection = self.args.table_name
                db_config.summaries_collection = f"{self.args.table_name}_summaries"
                db_config.logs_collection = f"{self.args.table_name}_logs"
                self.logger.info(f"üìã Utilisation de la collection: {self.args.table_name}")
            
            db_service = DatabaseService(db_config)
            db_service.connect()
            
            # Les noms des collections sont maintenant configur√©s automatiquement
            # via la configuration, mais on peut encore les surcharger si n√©cessaire
            if self.args.table_name:
                db_service.set_collection_names(
                    properties_collection=self.args.table_name,
                    summaries_collection=f"{self.args.table_name}_summaries",
                    logs_collection=f"{self.args.table_name}_logs"
                )
            
            db_service.ensure_indexes()
            self.logger.info("‚úÖ Base de donn√©es configur√©e avec succ√®s")
            return db_service
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la configuration de la base de donn√©es: {str(e)}")
            raise
    
    async def extract_property_summaries(
        self,
        location: str,
        property_type: PropertyType,
        extractor: CentrisExtractor
    ) -> List[PropertySummary]:
        """Extrait les r√©sum√©s de propri√©t√©s pour une localisation et un type donn√©s"""
        self.logger.info(f"üîç Extraction des r√©sum√©s pour {location} - {property_type}")
        
        try:
            # Cr√©ation de la requ√™te de recherche
            search_query = SearchQuery(
                locations=[location],
                property_types=[property_type],
                price_min=config.centris.sale_price_min,
                price_max=config.centris.sale_price_max
            )
            
            # Extraction des r√©sum√©s
            summaries = await extractor.extract_summaries(search_query)
            self.logger.info(f"‚úÖ {len(summaries)} r√©sum√©s extraits pour {location} - {property_type}")
            
            return summaries
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de l'extraction des r√©sum√©s: {str(e)}")
            raise
    
    async def extract_property_details(
        self,
        property_summary: PropertySummary,
        extractor: CentrisExtractor
    ) -> Optional[Property]:
        """Extrait les d√©tails complets d'une propri√©t√©"""
        self.logger.debug(f"üîç Extraction des d√©tails pour {property_summary.id}")
        
        try:
            if not property_summary.url:
                self.logger.warning(f"‚ö†Ô∏è Pas d'URL pour la propri√©t√© {property_summary.id}")
                return None
            
            property_details = await extractor.extract_details(property_summary.url)
            
            if property_details:
                self.logger.debug(f"‚úÖ D√©tails extraits pour {property_summary.id}")
                return property_details
            else:
                self.logger.warning(f"‚ö†Ô∏è Aucun d√©tail extrait pour {property_summary.id}")
                return None
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de l'extraction des d√©tails pour {property_summary.id}: {str(e)}")
            return None
    
    async def save_property(
        self,
        property_data: Property,
        db_service: DatabaseService
    ) -> bool:
        """Sauvegarde une propri√©t√© dans la base de donn√©es"""
        try:
            success = db_service.save_property(property_data)
            if success:
                self.logger.debug(f"üíæ Propri√©t√© {property_data.id} sauvegard√©e avec succ√®s")
            else:
                self.logger.warning(f"‚ö†Ô∏è √âchec de la sauvegarde pour {property_data.id}")
            return success
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de la sauvegarde de {property_data.id}: {str(e)}")
            return False
    
    async def process_location_property_type(
        self,
        location: str,
        property_type: PropertyType,
        db_service: DatabaseService
    ) -> Dict[str, Any]:
        """Traite une combinaison localisation/type de propri√©t√© compl√®te"""
        self.logger.info(f"üöÄ D√©but du traitement pour {location} - {property_type}")
        
        start_time = datetime.now()
        
        try:
            # Initialisation de l'extracteur
            extractor = CentrisExtractor(config.centris)
            
            # Extraction des r√©sum√©s
            summaries = await self.extract_property_summaries(location, property_type, extractor)
            
            if not summaries:
                self.logger.info(f"‚ÑπÔ∏è Aucune propri√©t√© trouv√©e pour {location} - {property_type}")
                return {
                    "location": location,
                    "property_type": property_type,
                    "summaries_count": 0,
                    "details_count": 0,
                    "success_count": 0,
                    "duration": datetime.now() - start_time
                }
            
            # Extraction des d√©tails en parall√®le
            self.logger.info(f"üîç Extraction des d√©tails pour {len(summaries)} propri√©t√©s...")
            
            # Traitement par lots pour √©viter la surcharge
            batch_size = config.batch_size
            total_details = 0
            total_success = 0
            
            for i in range(0, len(summaries), batch_size):
                if not self.running:
                    self.logger.info("‚ö†Ô∏è Arr√™t demand√©, traitement interrompu")
                    break
                
                batch = summaries[i:i + batch_size]
                self.logger.info(f"üì¶ Traitement du lot {i//batch_size + 1}/{(len(summaries) + batch_size - 1)//batch_size}")
                
                # Extraction des d√©tails pour ce lot
                detail_tasks = []
                for summary in batch:
                    task = asyncio.create_task(
                        self.extract_property_details(summary, extractor)
                    )
                    detail_tasks.append(task)
                
                # Attendre la completion de tous les d√©tails du lot
                batch_details = []
                for task in asyncio.as_completed(detail_tasks):
                    if not self.running:
                        break
                    result = await task
                    if result:
                        batch_details.append(result)
                
                total_details += len(batch_details)
                
                # Sauvegarde des propri√©t√©s du lot
                save_tasks = []
                for property_data in batch_details:
                    task = asyncio.create_task(
                        self.save_property(property_data, db_service)
                    )
                    save_tasks.append(task)
                
                # Compter les succ√®s
                batch_successes = []
                for task in asyncio.as_completed(save_tasks):
                    if not self.running:
                        break
                    result = await task
                    batch_successes.append(result)
                
                total_success += sum(batch_successes)
                
                # Pause entre les lots pour √©viter la surcharge
                if i + batch_size < len(summaries) and self.running:
                    self.logger.info("‚è≥ Pause entre les lots...")
                    await asyncio.sleep(2)
            
            duration = datetime.now() - start_time
            
            self.logger.info(f"‚úÖ Traitement termin√© pour {location} - {property_type}")
            self.logger.info(f"üìä R√©sultats: {len(summaries)} r√©sum√©s, {total_details} d√©tails, {total_success} sauvegard√©s")
            self.logger.info(f"‚è±Ô∏è Dur√©e: {duration}")
            
            return {
                "location": location,
                "property_type": property_type,
                "summaries_count": len(summaries),
                "details_count": total_details,
                "success_count": total_success,
                "duration": duration
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors du traitement de {location} - {property_type}: {str(e)}")
            raise
    
    async def run_pipeline(self) -> Dict[str, Any]:
        """Ex√©cute le pipeline principal d'extraction immobili√®re"""
        self.logger.info("üöÄ D√©marrage du pipeline d'extraction immobili√®re")
        
        start_time = datetime.now()
        
        try:
            # Configuration de la base de donn√©es
            self.db_service = await self.setup_database()
            
            # Filtrage des localisations et types selon les param√®tres
            locations_to_process = self._filter_locations()
            property_types_to_process = self._filter_property_types()
            
            self.logger.info(f"üéØ Traitement de {len(locations_to_process)} localisations et {len(property_types_to_process)} types de propri√©t√©s")
            
            # Traitement de toutes les combinaisons localisation/type
            results = []
            
            for location_config in locations_to_process:
                location_name = location_config.value
                
                for property_type_str in property_types_to_process:
                    if not self.running:
                        break
                    
                    try:
                        property_type = PropertyType(property_type_str)
                        
                        self.logger.info(f"üéØ Traitement de {location_name} - {property_type}")
                        
                        result = await self.process_location_property_type(
                            location_name,
                            property_type,
                            self.db_service
                        )
                        results.append(result)
                        
                    except ValueError as e:
                        self.logger.error(f"‚ùå Type de propri√©t√© invalide: {property_type_str}")
                        continue
                    except Exception as e:
                        self.logger.error(f"‚ùå Erreur lors du traitement de {location_name} - {property_type_str}: {str(e)}")
                        continue
                
                if not self.running:
                    break
            
            # R√©sum√© final
            total_summaries = sum(r["summaries_count"] for r in results)
            total_details = sum(r["details_count"] for r in results)
            total_success = sum(r["success_count"] for r in results)
            total_duration = datetime.now() - start_time
            
            if self.running:
                self.logger.info("üéâ Pipeline termin√© avec succ√®s!")
            else:
                self.logger.info("‚ö†Ô∏è Pipeline interrompu par l'utilisateur")
            
            self.logger.info(f"üìä R√©sum√© global:")
            self.logger.info(f"   - R√©sum√©s extraits: {total_summaries}")
            self.logger.info(f"   - D√©tails extraits: {total_details}")
            self.logger.info(f"   - Propri√©t√©s sauvegard√©es: {total_success}")
            self.logger.info(f"   - Dur√©e totale: {total_duration}")
            
            return {
                "success": self.running,
                "interrupted": not self.running,
                "results": results,
                "summary": {
                    "total_summaries": total_summaries,
                    "total_details": total_details,
                    "total_success": total_success,
                    "total_duration": total_duration
                }
            }
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur fatale dans le pipeline: {str(e)}")
            raise
        finally:
            # Fermeture de la connexion √† la base de donn√©es
            if self.db_service:
                self.db_service.close()
    
    def _filter_locations(self) -> List:
        """Filtre les localisations selon les param√®tres de ligne de commande"""
        all_locations = config.centris.locations_searched
        
        if self.args.location:
            # Filtrer par nom de localisation
            filtered = [loc for loc in all_locations if loc.value.lower() in self.args.location.lower()]
            if not filtered:
                self.logger.warning(f"‚ö†Ô∏è Aucune localisation trouv√©e pour '{self.args.location}'")
                return []
            return filtered
        
        if self.args.region:
            # Filtrer par r√©gion
            filtered = [loc for loc in all_locations if loc.region.lower() in self.args.region.lower()]
            if not filtered:
                self.logger.warning(f"‚ö†Ô∏è Aucune localisation trouv√©e pour la r√©gion '{self.args.region}'")
                return []
            return filtered
        
        # Retourner toutes les localisations si aucun filtre
        return all_locations
    
    def _filter_property_types(self) -> List[str]:
        """Filtre les types de propri√©t√©s selon les param√®tres de ligne de commande"""
        all_types = config.centris.property_types
        
        if self.args.property_type:
            # Filtrer par type de propri√©t√©
            filtered = [pt for pt in all_types if pt.lower() in self.args.property_type.lower()]
            if not filtered:
                self.logger.warning(f"‚ö†Ô∏è Aucun type de propri√©t√© trouv√© pour '{self.args.property_type}'")
                return []
            return filtered
        
        # Retourner tous les types si aucun filtre
        return all_types


def parse_arguments():
    """Parse les arguments de ligne de commande"""
    parser = argparse.ArgumentParser(
        description="Pipeline d'extraction web immobili√®re",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  # Ex√©cution compl√®te
  python scripts/run_pipeline.py
  
  # Extraction pour une localisation sp√©cifique
  python scripts/run_pipeline.py --location "Montr√©al"
  
  # Extraction pour un type de propri√©t√© sp√©cifique
  python scripts/run_pipeline.py --property-type "Condo"
  
  # Extraction pour une r√©gion sp√©cifique
  python scripts/run_pipeline.py --region "Qu√©bec"
  
  # Mode debug avec plus de logs
  python scripts/run_pipeline.py --debug
  
  # Limitation du nombre de propri√©t√©s
  python scripts/run_pipeline.py --max-properties 100
  
  # Sp√©cification du nom de la table/collection
  python scripts/run_pipeline.py --table-name "properties_2024"
        """
    )
    
    # Filtres de localisation
    location_group = parser.add_mutually_exclusive_group()
    location_group.add_argument(
        '--location', '-l',
        type=str,
        help='Localisation sp√©cifique √† traiter (ex: "Montr√©al", "Laval")'
    )
    location_group.add_argument(
        '--region', '-r',
        type=str,
        help='R√©gion sp√©cifique √† traiter (ex: "Qu√©bec", "Ontario")'
    )
    
    # Filtres de propri√©t√©
    parser.add_argument(
        '--property-type', '-t',
        type=str,
        help='Type de propri√©t√© sp√©cifique √† traiter (ex: "Condo", "House")'
    )
    
    # Options de base de donn√©es
    parser.add_argument(
        '--table-name', '-n',
        type=str,
        help='Nom de la table/collection MongoDB (ex: "properties_2024", "real_estate_data")'
    )
    parser.add_argument(
        '--database-name',
        type=str,
        help='Nom de la base de donn√©es MongoDB (ex: "real_estate_db", "property_data")'
    )
    
    # Options de performance
    parser.add_argument(
        '--max-properties',
        type=int,
        help='Nombre maximum de propri√©t√©s √† traiter'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        help='Taille des lots de traitement'
    )
    
    # Options de debug
    parser.add_argument(
        '--debug', '-d',
        action='store_true',
        help='Mode debug avec logs d√©taill√©s'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Simulation sans sauvegarde en base'
    )
    
    # Options de sortie
    parser.add_argument(
        '--output-format',
        choices=['json', 'csv', 'console'],
        default='console',
        help='Format de sortie des r√©sultats'
    )
    parser.add_argument(
        '--output-file',
        type=str,
        help='Fichier de sortie pour les r√©sultats'
    )
    
    return parser.parse_args()


async def main():
    """Fonction principale asynchrone"""
    # Parse des arguments
    args = parse_arguments()
    
    # Configuration du logging selon le mode debug
    log_level = "DEBUG" if args.debug else config.log_level
    setup_logging(
        log_level=log_level,
        log_file=config.log_file,
        log_format="json"
    )
    
    # Application des param√®tres de ligne de commande
    if args.batch_size:
        config.batch_size = args.batch_size
    
    # Application des param√®tres de base de donn√©es
    if args.database_name:
        config.database.database_name = args.database_name
    
    with LogContext("pipeline_execution", args=vars(args)):
        try:
            # Cr√©ation et ex√©cution du pipeline
            executor = PipelineExecutor(args)
            result = await executor.run_pipeline()
            
            # Affichage des r√©sultats
            display_results(result, args)
            
            # Code de sortie appropri√©
            if result.get("success"):
                print("üéâ Pipeline ex√©cut√© avec succ√®s!")
                sys.exit(0)
            elif result.get("interrupted"):
                print("‚ö†Ô∏è Pipeline interrompu par l'utilisateur")
                sys.exit(130)
            else:
                print("‚ùå Pipeline √©chou√©")
                sys.exit(1)
                
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è Pipeline interrompu par l'utilisateur")
            sys.exit(130)
        except Exception as e:
            print(f"‚ùå Erreur fatale: {str(e)}")
            sys.exit(1)


def display_results(result: Dict[str, Any], args):
    """Affiche les r√©sultats selon le format demand√©"""
    if args.output_format == 'json':
        import json
        output = json.dumps(result, indent=2, default=str)
        
        if args.output_file:
            with open(args.output_file, 'w', encoding='utf-8') as f:
                f.write(output)
            print(f"üìÑ R√©sultats sauvegard√©s dans {args.output_file}")
        else:
            print(output)
    
    elif args.output_format == 'csv':
        import csv
        output_file = args.output_file or 'pipeline_results.csv'
        
        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['Location', 'Property Type', 'Summaries', 'Details', 'Success', 'Duration'])
            
            for r in result.get('results', []):
                writer.writerow([
                    r['location'],
                    r['property_type'],
                    r['summaries_count'],
                    r['details_count'],
                    r['success_count'],
                    str(r['duration'])
                ])
        
        print(f"üìÑ R√©sultats sauvegard√©s dans {output_file}")
    
    else:  # console
        print("\nüìä R√©sultats du pipeline:")
        print("=" * 50)
        
        for r in result.get('results', []):
            print(f"üìç {r['location']} - {r['property_type']}")
            print(f"   üìã R√©sum√©s: {r['summaries_count']}")
            print(f"   üîç D√©tails: {r['details_count']}")
            print(f"   üíæ Sauvegard√©s: {r['success_count']}")
            print(f"   ‚è±Ô∏è Dur√©e: {r['duration']}")
            print("-" * 30)
        
        summary = result.get('summary', {})
        print(f"\nüéØ R√©sum√© global:")
        print(f"   Total r√©sum√©s: {summary.get('total_summaries', 0)}")
        print(f"   Total d√©tails: {summary.get('total_details', 0)}")
        print(f"   Total sauvegard√©s: {summary.get('total_success', 0)}")
        print(f"   Dur√©e totale: {summary.get('total_duration', 'N/A')}")


def run_sync():
    """Version synchrone pour compatibilit√©"""
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    run_sync()
