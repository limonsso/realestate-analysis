{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸ  Exemple d'Analyse des PropriÃ©tÃ©s - Pipeline en 5 Ã‰tapes\n",
        "\n",
        "Ce notebook dÃ©montre l'utilisation de la fonction `analyze_properties` corrigÃ©e qui respecte les 5 Ã©tapes dÃ©finies :\n",
        "\n",
        "1. **ğŸ§¹ Nettoyage des donnÃ©es**\n",
        "   - Suppression des colonnes avec trop de valeurs manquantes\n",
        "   - Suppression des colonnes non pertinentes (IDs, liens, etc.)\n",
        "\n",
        "2. **ğŸ·ï¸ Classification des propriÃ©tÃ©s**\n",
        "   - Analyse du type de propriÃ©tÃ© (`type` column)\n",
        "   - Classification automatique : RÃ©sidentiel, Revenu, Autres\n",
        "\n",
        "3. **ğŸ”§ PrÃ©paration des donnÃ©es**\n",
        "   - Encodage des variables catÃ©gorielles\n",
        "   - Imputation des valeurs manquantes\n",
        "   - Normalisation si nÃ©cessaire\n",
        "\n",
        "4. **ğŸ¯ SÃ©lection des variables**\n",
        "   - MÃ©thode **Lasso** : RÃ©gularisation L1 pour Ã©liminer les variables non significatives\n",
        "   - MÃ©thode **Random Forest** : Importance des variables basÃ©e sur les arbres\n",
        "   - **Combinaison** des deux approches pour un rÃ©sultat optimal\n",
        "\n",
        "5. **ğŸ“Š Analyse des rÃ©sultats**\n",
        "   - Statistiques par type de propriÃ©tÃ©\n",
        "   - Variables sÃ©lectionnÃ©es et leur importance\n",
        "   - MÃ©triques de performance des modÃ¨les\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“¥ Chargement des DonnÃ©es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“Š Chargement des donnÃ©es depuis MongoDB\n",
        "from lib.db import read_mongodb_to_dataframe\n",
        "\n",
        "print(\"ğŸ”„ Connexion Ã  MongoDB et chargement des donnÃ©es...\")\n",
        "\n",
        "# Chargement des propriÃ©tÃ©s vendues\n",
        "properties_db = read_mongodb_to_dataframe(\n",
        "    db='real_estate_db', \n",
        "    collection='properties', \n",
        "    query={'vendue': True},  # Filtre pour les propriÃ©tÃ©s vendues uniquement\n",
        "    no_id=False  # Garder l'ID pour rÃ©fÃ©rence\n",
        ")\n",
        "\n",
        "print(f\"âœ… DonnÃ©es chargÃ©es avec succÃ¨s!\")\n",
        "print(f\"ğŸ“Š Nombre de propriÃ©tÃ©s: {len(properties_db):,}\")\n",
        "print(f\"ğŸ“‹ Nombre de colonnes: {len(properties_db.columns)}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ”§ Configuration de l'Analyseur\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ“¦ Import des classes modulaires\n",
        "from lib.property_analysis import (\n",
        "    PropertyAnalyzer, \n",
        "    PropertyDataProcessor, \n",
        "    PropertyClassifier, \n",
        "    FeatureSelector\n",
        ")\n",
        "\n",
        "print(\"ğŸ“¦ Classes modulaires importÃ©es avec succÃ¨s!\")\n",
        "\n",
        "# Configuration du processeur de donnÃ©es\n",
        "data_processor = PropertyDataProcessor(\n",
        "    missing_threshold=0.05  # Supprimer les colonnes avec >95% de valeurs manquantes\n",
        ")\n",
        "\n",
        "# Configuration du classificateur de propriÃ©tÃ©s\n",
        "property_classifier = PropertyClassifier()\n",
        "\n",
        "# Configuration du sÃ©lecteur de variables\n",
        "feature_selector = FeatureSelector(\n",
        "    cv_folds=5,              # Validation croisÃ©e 5-folds\n",
        "    random_state=42,         # ReproductibilitÃ©\n",
        "    max_iter=10000,          # Convergence Lasso\n",
        "    tolerance=1e-3,          # TolÃ©rance de convergence\n",
        "    rf_n_estimators=100,     # Nombre d'arbres Random Forest\n",
        "    rf_threshold=0.01        # Seuil d'importance des variables\n",
        ")\n",
        "\n",
        "# CrÃ©ation de l'analyseur principal avec injection de dÃ©pendances\n",
        "analyzer = PropertyAnalyzer(\n",
        "    data_processor=data_processor,\n",
        "    property_classifier=property_classifier,\n",
        "    feature_selector=feature_selector\n",
        ")\n",
        "\n",
        "print(\"âœ… Analyseur configurÃ© et prÃªt!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš€ ExÃ©cution du Pipeline en 5 Ã‰tapes\n",
        "\n",
        "**Attention:** Cette cellule exÃ©cute maintenant la fonction `analyze_properties` corrigÃ©e qui respecte exactement les 5 Ã©tapes dÃ©finies et rÃ©sout les problÃ¨mes d'encodage des variables catÃ©gorielles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸš€ ExÃ©cution du pipeline complet d'analyse\n",
        "print(\"ğŸ”„ Lancement de l'analyse automatisÃ©e en 5 Ã©tapes...\")\n",
        "\n",
        "try:\n",
        "    # ExÃ©cution de l'analyse complÃ¨te avec la fonction corrigÃ©e\n",
        "    results = analyzer.analyze_properties(properties_db, target_column='price')\n",
        "    \n",
        "    print(f\"\\nğŸ‰ === PIPELINE TERMINÃ‰ AVEC SUCCÃˆS ===\")\n",
        "    print(f\"âœ… Toutes les 5 Ã©tapes ont Ã©tÃ© exÃ©cutÃ©es:\")\n",
        "    print(f\"   1. ğŸ§¹ Nettoyage des donnÃ©es\")\n",
        "    print(f\"   2. ğŸ·ï¸ Classification des propriÃ©tÃ©s\")  \n",
        "    print(f\"   3. ğŸ”§ PrÃ©paration des donnÃ©es\")\n",
        "    print(f\"   4. ğŸ¯ SÃ©lection des variables\")\n",
        "    print(f\"   5. ğŸ“Š Analyse des rÃ©sultats\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erreur durante l'analyse: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š AccÃ¨s aux RÃ©sultats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ Variables disponibles pour les Ã©tapes suivantes\n",
        "if 'results' in locals():\n",
        "    X = analyzer.processed_data['X']\n",
        "    y = analyzer.processed_data['y']\n",
        "    df_classified = analyzer.processed_data['df_classified']\n",
        "    df_prepared = analyzer.processed_data['df_prepared']\n",
        "    important_features = results['selected_features']\n",
        "    \n",
        "    print(f\"ğŸ“‹ === RÃ‰SULTATS DE L'ANALYSE ===\")\n",
        "    \n",
        "    # Forme des donnÃ©es\n",
        "    print(f\"\\nğŸ  Transformation des donnÃ©es:\")\n",
        "    print(f\"   ğŸ“Š Originales: {results['shape_original']}\")\n",
        "    print(f\"   ğŸ“Š TraitÃ©es: {results['shape_processed']}\")\n",
        "    \n",
        "    # Classification des propriÃ©tÃ©s\n",
        "    print(f\"\\nğŸ·ï¸ Classification des propriÃ©tÃ©s:\")\n",
        "    for category, count in results['classification_stats']['counts'].items():\n",
        "        pct = results['classification_stats']['percentages'][category]\n",
        "        print(f\"   ğŸ  {category}: {count:,} propriÃ©tÃ©s ({pct:.1f}%)\")\n",
        "    \n",
        "    # Variables sÃ©lectionnÃ©es\n",
        "    print(f\"\\nğŸ¯ Variables sÃ©lectionnÃ©es:\")\n",
        "    print(f\"   ğŸ“ˆ Total: {len(results['selected_features'])} variables\")\n",
        "    print(f\"   ğŸ“ Variables: {results['selected_features'][:10]}...\")  # Afficher les 10 premiÃ¨res\n",
        "    \n",
        "    # Importance des variables\n",
        "    if results['feature_importance']:\n",
        "        print(f\"\\nğŸŒŸ Top 5 des variables les plus importantes:\")\n",
        "        sorted_importance = sorted(results['feature_importance'].items(), key=lambda x: x[1], reverse=True)\n",
        "        for i, (feature, importance) in enumerate(sorted_importance[:5], 1):\n",
        "            print(f\"   {i}. {feature}: {importance:.4f}\")\n",
        "    \n",
        "    # RÃ©sumÃ© final\n",
        "    summary = analyzer.get_summary()\n",
        "    print(f\"\\nğŸ“ˆ === RÃ‰SUMÃ‰ FINAL ===\")\n",
        "    print(f\"   ğŸ  Total propriÃ©tÃ©s: {summary['total_properties']:,}\")\n",
        "    print(f\"   ğŸ“Š Features totales: {summary['total_features']}\")\n",
        "    print(f\"   ğŸ¯ Features sÃ©lectionnÃ©es: {summary['selected_features_count']}\")\n",
        "    print(f\"   ğŸ“‰ RÃ©duction: {summary['reduction_percentage']:.1f}%\")\n",
        "    print(f\"   ğŸ’° Prix moyen: {summary['price_stats']['mean']:,.2f}$\")\n",
        "    \n",
        "    print(f\"\\nğŸ”§ Variables disponibles pour la suite:\")\n",
        "    print(f\"   ğŸ“Š X: Matrice des features ({X.shape})\")\n",
        "    print(f\"   ğŸ¯ y: Vecteur cible ({y.shape})\")\n",
        "    print(f\"   ğŸ  df_classified: DataFrame avec classification ({df_classified.shape})\")\n",
        "    print(f\"   ğŸ› ï¸  df_prepared: DataFrame prÃ©parÃ© pour ML ({df_prepared.shape})\")\n",
        "    print(f\"   ğŸ“ important_features: Liste des variables importantes\")\n",
        "else:\n",
        "    print(\"âŒ Aucun rÃ©sultat disponible - L'analyse a probablement Ã©chouÃ©\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“ AmÃ©liorations ApportÃ©es\n",
        "\n",
        "### âœ… Corrections dans la Fonction `analyze_properties`\n",
        "\n",
        "1. **ğŸ§¹ Structure des 5 Ã‰tapes RespectÃ©e**\n",
        "   - RÃ©organisation exacte selon vos spÃ©cifications\n",
        "   - Messages clairs pour chaque Ã©tape\n",
        "\n",
        "2. **ğŸ”§ RÃ©solution du ProblÃ¨me d'Encodage**\n",
        "   - VÃ©rification que toutes les variables sont numÃ©riques avant ML\n",
        "   - Conversion forcÃ©e des variables non-numÃ©riques avec `pd.to_numeric()`\n",
        "   - Suppression des colonnes qui ne peuvent pas Ãªtre converties\n",
        "   - Imputation des NaN crÃ©Ã©s par la conversion\n",
        "\n",
        "3. **ğŸ›¡ï¸ Gestion d'Erreurs Robuste**\n",
        "   - Try-catch autour de la sÃ©lection de variables\n",
        "   - Fallback vers toutes les variables si sÃ©lection Ã©choue\n",
        "   - Messages d'erreur informatifs\n",
        "\n",
        "4. **ğŸ“Š Affichage AmÃ©liorÃ©**\n",
        "   - Progress indicators pour chaque Ã©tape\n",
        "   - Statistiques dÃ©taillÃ©es des transformations\n",
        "   - Top 5 des variables les plus importantes\n",
        "\n",
        "### ğŸš€ Prochaines Ã‰tapes\n",
        "\n",
        "- Testez le notebook avec vos donnÃ©es\n",
        "- Ajustez les paramÃ¨tres selon vos besoins\n",
        "- Utilisez `important_features` pour la modÃ©lisation\n",
        "- Adaptez les seuils de classification si nÃ©cessaire\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸ“Š Analyse ImmobiliÃ¨re - Ã‰tapes Individuelles\n",
        "\n",
        "Ce notebook montre comment exÃ©cuter chaque Ã©tape de l'analyse immobiliÃ¨re individuellement.\n",
        "Cela permet un meilleur contrÃ´le et debugging de chaque Ã©tape du processus.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ”§ Configuration et Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lib import PropertyAnalyzer, MongoDBLoader\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Option 1: Avec donnÃ©es MongoDB (recommandÃ©)\n",
        "# loader = MongoDBLoader()\n",
        "# property_types = loader.load_property_types()\n",
        "# analyzer = PropertyAnalyzer(property_types_data=property_types)\n",
        "\n",
        "# Option 2: Avec donnÃ©es d'exemple pour la normalisation des types\n",
        "property_types_example = [\n",
        "    {\n",
        "        \"_id\": \"maison\",\n",
        "        \"display_names\": {\"fr\": \"Maison\", \"en\": \"House\"},\n",
        "        \"category\": \"RÃ©sidentiel\",\n",
        "        \"typical_characteristics\": [\"living_area\", \"lot_size\", \"bedrooms\", \"bathrooms\"]\n",
        "    },\n",
        "    {\n",
        "        \"_id\": \"condo\",\n",
        "        \"display_names\": {\"fr\": \"Condo\", \"en\": \"Condominium\"},\n",
        "        \"category\": \"RÃ©sidentiel\",\n",
        "        \"typical_characteristics\": [\"living_area\", \"bedrooms\", \"bathrooms\"]\n",
        "    },\n",
        "    {\n",
        "        \"_id\": \"duplex\",\n",
        "        \"display_names\": {\"fr\": \"Duplex\", \"en\": \"Duplex\"},\n",
        "        \"category\": \"RÃ©sidentiel\",\n",
        "        \"typical_characteristics\": [\"living_area\", \"lot_size\", \"bedrooms\", \"bathrooms\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Option 3: Sans donnÃ©es de types (utilise la normalisation basique)\n",
        "# analyzer = PropertyAnalyzer()\n",
        "\n",
        "# Initialiser l'analyseur avec les donnÃ©es de types\n",
        "analyzer = PropertyAnalyzer(property_types_data=property_types_example)\n",
        "\n",
        "print(\"ğŸ  Analyseur immobilier initialisÃ© avec succÃ¨s!\")\n",
        "print(\"ğŸ”„ Normalisateur de types de propriÃ©tÃ©s configurÃ©!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“¥ Chargement des DonnÃ©es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Charger depuis MongoDB\n",
        "# loader = MongoDBLoader()\n",
        "# df = loader.load_properties()\n",
        "# property_types = loader.load_property_types()\n",
        "\n",
        "# Option 2: Charger depuis un fichier CSV/Excel\n",
        "# df = pd.read_csv('votre_fichier.csv')\n",
        "\n",
        "# Option 3: Utiliser des donnÃ©es d'exemple (pour test)\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'price': np.random.normal(500000, 150000, n_samples),\n",
        "    'living_area': np.random.normal(1500, 400, n_samples),\n",
        "    'lot_size': np.random.normal(5000, 2000, n_samples),\n",
        "    'bedrooms': np.random.randint(1, 6, n_samples),\n",
        "    'bathrooms': np.random.randint(1, 4, n_samples),\n",
        "    'year_built': np.random.randint(1950, 2024, n_samples),\n",
        "    'type': np.random.choice(['maison', 'condo', 'duplex'], n_samples),\n",
        "    'city': np.random.choice(['Montreal', 'Quebec', 'Laval', 'Gatineau'], n_samples),\n",
        "    'region': np.random.choice(['Montreal', 'Quebec', 'Outaouais'], n_samples),\n",
        "    'building_style': np.random.choice(['contemporain', 'traditionnel', 'moderne'], n_samples),\n",
        "    'municipal_evaluation_total': np.random.normal(450000, 120000, n_samples),\n",
        "    # Colonnes Ã  supprimer (simulation donnÃ©es MongoDB)\n",
        "    '_id': range(n_samples),\n",
        "    'link': ['http://example.com'] * n_samples,\n",
        "    'images': [['img1.jpg', 'img2.jpg']] * n_samples,\n",
        "    'extraction_metadata': [{'date': '2024-01-01'}] * n_samples\n",
        "})\n",
        "\n",
        "# Ajouter quelques valeurs manquantes\n",
        "df.loc[df.sample(50).index, 'lot_size'] = np.nan\n",
        "df.loc[df.sample(30).index, 'year_built'] = np.nan\n",
        "\n",
        "print(f\"ğŸ“Š DonnÃ©es chargÃ©es: {df.shape}\")\n",
        "print(f\"ğŸ“ Colonnes: {list(df.columns)}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Ã‰TAPE 1: Validation et Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valider et explorer les donnÃ©es\n",
        "df_step1 = analyzer.validate_and_explore(df, target_column='price')\n",
        "\n",
        "# Vous pouvez ajouter votre propre exploration ici\n",
        "print(\"\\nğŸ” Exploration supplÃ©mentaire:\")\n",
        "print(f\"Types de donnÃ©es:\")\n",
        "print(df_step1.dtypes)\n",
        "\n",
        "print(f\"\\nValeurs manquantes par colonne:\")\n",
        "print(df_step1.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ§¹ Ã‰TAPE 2: Nettoyage des DonnÃ©es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nettoyer les donnÃ©es\n",
        "df_step2 = analyzer.clean_data(df_step1)\n",
        "\n",
        "print(\"\\nğŸ” VÃ©rification aprÃ¨s nettoyage:\")\n",
        "print(f\"Colonnes restantes: {list(df_step2.columns)}\")\n",
        "print(f\"Forme des donnÃ©es: {df_step2.shape}\")\n",
        "\n",
        "df_step2.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ”„ Ã‰TAPE 3: Normalisation des Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normaliser les variables catÃ©gorielles\n",
        "df_step3 = analyzer.normalize_variables(df_step2)\n",
        "\n",
        "print(\"\\nğŸ” VÃ©rification aprÃ¨s normalisation:\")\n",
        "print(f\"Colonnes: {list(df_step3.columns)}\")\n",
        "\n",
        "# VÃ©rifier les changements dans les variables catÃ©gorielles\n",
        "categorical_cols = df_step3.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\nğŸ“Š Variable '{col}':\")\n",
        "    print(f\"   Valeurs uniques: {df_step3[col].nunique()}\")\n",
        "    print(f\"   Valeurs: {list(df_step3[col].unique())}\")\n",
        "\n",
        "df_step3.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ”¢ Ã‰TAPE 4: Encodage des Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encoder les variables catÃ©gorielles\n",
        "df_step4 = analyzer.encode_features(df_step3)\n",
        "\n",
        "print(\"\\nğŸ” VÃ©rification aprÃ¨s encodage:\")\n",
        "print(f\"Nouvelles colonnes: {list(df_step4.columns)}\")\n",
        "print(f\"Types de donnÃ©es aprÃ¨s encodage:\")\n",
        "print(df_step4.dtypes)\n",
        "\n",
        "df_step4.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ”§ Ã‰TAPE 5: Imputation des Valeurs Manquantes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imputer les valeurs manquantes\n",
        "df_step5 = analyzer.impute_missing_values(df_step4)\n",
        "\n",
        "print(\"\\nğŸ” VÃ©rification aprÃ¨s imputation:\")\n",
        "print(f\"Valeurs manquantes restantes: {df_step5.isnull().sum().sum()}\")\n",
        "print(f\"Statistiques des colonnes imputÃ©es:\")\n",
        "print(df_step5.describe())\n",
        "\n",
        "df_step5.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ  Ã‰TAPE 6: Classification des PropriÃ©tÃ©s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classifier les propriÃ©tÃ©s\n",
        "df_step6 = analyzer.classify_properties(df_step5)\n",
        "\n",
        "print(\"\\nğŸ” VÃ©rification de la classification:\")\n",
        "print(f\"Nouvelle colonne: 'classification_immobiliere'\")\n",
        "print(f\"Distribution des classifications:\")\n",
        "print(df_step6['classification_immobiliere'].value_counts())\n",
        "\n",
        "# Visualiser la distribution des prix par classification\n",
        "print(\"\\nğŸ’° Prix moyen par catÃ©gorie:\")\n",
        "price_by_class = df_step6.groupby('classification_immobiliere')['price'].agg(['mean', 'median', 'count'])\n",
        "print(price_by_class)\n",
        "\n",
        "df_step6.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¯ Ã‰TAPE 7: PrÃ©paration pour la ModÃ©lisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PrÃ©parer les donnÃ©es pour la modÃ©lisation\n",
        "X, y = analyzer.prepare_for_modeling(df_step6, target_column='price')\n",
        "\n",
        "print(\"\\nğŸ” VÃ©rification des donnÃ©es prÃ©parÃ©es:\")\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "print(f\"\\nColonnes features:\")\n",
        "for i, col in enumerate(X.columns, 1):\n",
        "    print(f\"  {i}. {col}\")\n",
        "\n",
        "print(f\"\\nStatistiques de la variable cible:\")\n",
        "print(y.describe())\n",
        "\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¯ Ã‰TAPE 8: SÃ©lection de Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SÃ©lectionner les variables importantes\n",
        "selected_features = analyzer.select_features(X, y)\n",
        "\n",
        "print(\"\\nğŸ” Analyse des variables sÃ©lectionnÃ©es:\")\n",
        "print(f\"Variables sÃ©lectionnÃ©es: {selected_features}\")\n",
        "\n",
        "# CrÃ©er un sous-ensemble avec seulement les variables sÃ©lectionnÃ©es\n",
        "X_selected = X[selected_features]\n",
        "print(f\"\\nNouveaux features (X_selected): {X_selected.shape}\")\n",
        "\n",
        "X_selected.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ  Ã‰TAPE 9: SÃ©lection par Type de PropriÃ©tÃ©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SÃ©lectionner les variables par type de propriÃ©tÃ©\n",
        "classification_features = analyzer.select_features_by_classification(\n",
        "    X, y, df_step6['classification_immobiliere']\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ” Analyse des variables par type:\")\n",
        "if classification_features:\n",
        "    for prop_type, features in classification_features.items():\n",
        "        print(f\"\\nğŸ·ï¸ {prop_type}:\")\n",
        "        print(f\"   Variables importantes: {features}\")\n",
        "        \n",
        "        # CrÃ©er un sous-ensemble pour ce type\n",
        "        mask = df_step6['classification_immobiliere'] == prop_type\n",
        "        X_type = X[mask][features]\n",
        "        y_type = y[mask]\n",
        "        print(f\"   DonnÃ©es pour ce type: X={X_type.shape}, y={y_type.shape}\")\n",
        "else:\n",
        "    print(\"Pas de sÃ©lection spÃ©cifique par type disponible\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Ã‰TAPE 10: Importance des Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer l'importance des variables\n",
        "feature_importance = analyzer.calculate_feature_importance(X, y)\n",
        "\n",
        "print(\"\\nğŸ” Analyse dÃ©taillÃ©e de l'importance:\")\n",
        "importance_df = pd.DataFrame([\n",
        "    {'feature': feature, 'importance': importance}\n",
        "    for feature, importance in feature_importance.items()\n",
        "]).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nğŸ“Š Tableau d'importance complet:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Visualisation simple\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_features = importance_df.head(10)\n",
        "plt.barh(range(len(top_features)), top_features['importance'])\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 10 Variables les Plus Importantes')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ† Ã‰TAPE 11: RÃ©sumÃ© Final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GÃ©nÃ©rer le rÃ©sumÃ© final\n",
        "final_results = analyzer.final_summary()\n",
        "\n",
        "print(\"\\nğŸ“‹ RÃ©sultats structurÃ©s:\")\n",
        "print(f\"RÃ©sultats disponibles: {final_results.keys()}\")\n",
        "\n",
        "# CrÃ©er un DataFrame de rÃ©sumÃ©\n",
        "summary_data = {\n",
        "    'MÃ©trique': [\n",
        "        'Lignes originales',\n",
        "        'Lignes aprÃ¨s traitement',\n",
        "        'Colonnes originales',\n",
        "        'Colonnes aprÃ¨s traitement',\n",
        "        'Variables sÃ©lectionnÃ©es',\n",
        "        'Taux de conservation des variables'\n",
        "    ],\n",
        "    'Valeur': [\n",
        "        final_results.get('shape_original', (0, 0))[0],\n",
        "        final_results.get('shape_processed', (0, 0))[0],\n",
        "        final_results.get('shape_original', (0, 0))[1],\n",
        "        final_results.get('shape_processed', (0, 0))[1],\n",
        "        len(final_results.get('selected_features', [])),\n",
        "        f\"{(len(final_results.get('selected_features', [])) / (final_results.get('shape_processed', (0, 1))[1] - 1) * 100):.1f}%\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\nğŸ“Š Tableau de rÃ©sumÃ©:\")\n",
        "print(summary_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Maintenant vous avez toutes les donnÃ©es prÃªtes pour la modÃ©lisation\n",
        "print(\"ğŸ¯ DonnÃ©es prÃªtes pour la modÃ©lisation:\")\n",
        "print(f\"\\nğŸ“Š X (features complÃ¨tes): {X.shape}\")\n",
        "print(f\"ğŸ“Š X_selected (features sÃ©lectionnÃ©es): {X_selected.shape}\")\n",
        "print(f\"ğŸ¯ y (target): {y.shape}\")\n",
        "print(f\"ğŸ  df_step6 (donnÃ©es complÃ¨tes avec classification): {df_step6.shape}\")\n",
        "\n",
        "print(f\"\\nâœ… Variables sÃ©lectionnÃ©es pour la modÃ©lisation:\")\n",
        "for i, feature in enumerate(selected_features, 1):\n",
        "    print(f\"  {i}. {feature}\")\n",
        "\n",
        "print(f\"\\nğŸ·ï¸ Classifications disponibles:\")\n",
        "for category, stats in final_results.get('classification_stats', {}).get('counts', {}).items():\n",
        "    print(f\"  â€¢ {category}: {stats} propriÃ©tÃ©s\")\n",
        "\n",
        "print(\"\\nğŸ‰ PrÃªt pour l'entraÃ®nement de modÃ¨les!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“ Notes et Prochaines Ã‰tapes\n",
        "\n",
        "### DonnÃ©es Disponibles:\n",
        "- `X`: Matrice complÃ¨te des features\n",
        "- `X_selected`: Matrice avec seulement les features sÃ©lectionnÃ©es\n",
        "- `y`: Vecteur target (prix)\n",
        "- `df_step6`: DataFrame complet avec classification\n",
        "- `selected_features`: Liste des variables importantes\n",
        "- `classification_features`: Variables par type de propriÃ©tÃ©\n",
        "- `feature_importance`: Importance de chaque variable\n",
        "\n",
        "### MÃ©thodes Disponibles (Noms SimplifiÃ©s):\n",
        "1. **`validate_and_explore()`** - Validation et exploration des donnÃ©es\n",
        "2. **`clean_data()`** - Nettoyage et suppression des colonnes inutiles\n",
        "3. **`normalize_variables()`** - ğŸ†• Standardisation des variables catÃ©gorielles\n",
        "4. **`encode_features()`** - Transformation en variables numÃ©riques\n",
        "5. **`impute_missing_values()`** - Traitement des valeurs manquantes\n",
        "6. **`classify_properties()`** - CatÃ©gorisation des propriÃ©tÃ©s\n",
        "7. **`prepare_for_modeling()`** - SÃ©paration features/target\n",
        "8. **`select_features()`** - SÃ©lection des variables importantes\n",
        "9. **`select_features_by_classification()`** - Variables spÃ©cifiques par catÃ©gorie\n",
        "10. **`calculate_feature_importance()`** - Calcul des scores d'importance\n",
        "11. **`final_summary()`** - SynthÃ¨se complÃ¨te\n",
        "\n",
        "### Utilisation SimplifiÃ©e:\n",
        "```python\n",
        "# Option 1: Avec normalisation avancÃ©e des types (recommandÃ©)\n",
        "from lib import MongoDBLoader\n",
        "loader = MongoDBLoader()\n",
        "property_types = loader.load_property_types()\n",
        "analyzer = PropertyAnalyzer(property_types_data=property_types)\n",
        "\n",
        "# Option 2: Avec donnÃ©es d'exemple\n",
        "property_types_example = [\n",
        "    {\"_id\": \"maison\", \"display_names\": {\"fr\": \"Maison\", \"en\": \"House\"}},\n",
        "    {\"_id\": \"condo\", \"display_names\": {\"fr\": \"Condo\", \"en\": \"Condominium\"}}\n",
        "]\n",
        "analyzer = PropertyAnalyzer(property_types_data=property_types_example)\n",
        "\n",
        "# Option 3: Sans normalisation avancÃ©e (fallback)\n",
        "analyzer = PropertyAnalyzer()\n",
        "\n",
        "# Utilisation standard\n",
        "df_step1 = analyzer.validate_and_explore(df, target_column='price')\n",
        "df_step2 = analyzer.clean_data(df_step1)\n",
        "df_step3 = analyzer.normalize_variables(df_step2)  # ğŸ†• Utilise PropertyTypeNormalizer\n",
        "df_step4 = analyzer.encode_features(df_step3)\n",
        "df_step5 = analyzer.impute_missing_values(df_step4)\n",
        "df_step6 = analyzer.classify_properties(df_step5)\n",
        "X, y = analyzer.prepare_for_modeling(df_step6, target_column='price')\n",
        "selected_features = analyzer.select_features(X, y)\n",
        "classification_features = analyzer.select_features_by_classification(X, y, df_step6['classification_immobiliere'])\n",
        "feature_importance = analyzer.calculate_feature_importance(X, y)\n",
        "final_results = analyzer.final_summary()\n",
        "```\n",
        "\n",
        "### Avantages des Nouveaux Noms:\n",
        "- âœ… **Plus intuitifs** : Noms descriptifs au lieu de step_1, step_2...\n",
        "- âœ… **Plus lisibles** : Code plus facile Ã  comprendre\n",
        "- âœ… **Plus maintenables** : Fonctions clairement identifiÃ©es\n",
        "- âœ… **Auto-documentÃ©s** : Le nom explique la fonction\n",
        "\n",
        "### Avantages de la Nouvelle Normalisation:\n",
        "\n",
        "#### ğŸ  **PropertyTypeNormalizer (Nouveau)**:\n",
        "- âœ… **Normalisation intelligente** : Utilise la collection `property_types` MongoDB\n",
        "- âœ… **Correspondance approximative** : \"Maison Ã  vendre\" â†’ \"maison\"\n",
        "- âœ… **Support multilingue** : FR/EN automatique\n",
        "- âœ… **Types inconnus gÃ©rÃ©s** : MarquÃ©s comme \"unknown\"\n",
        "- âœ… **Extensible** : Facilement personnalisable\n",
        "- âœ… **ID normalisÃ©s** : CrÃ©e une colonne `type_id` standardisÃ©e\n",
        "\n",
        "#### ğŸ™ï¸ **Autres Variables**:\n",
        "- âœ… **Villes corrigÃ©es** : \"Montreal\" â†’ \"MontrÃ©al\"\n",
        "- âœ… **RÃ©gions standardisÃ©es** : \"Monteregie\" â†’ \"MontÃ©rÃ©gie\"\n",
        "- âœ… **Styles uniformisÃ©s** : \"contemporary\" â†’ \"contemporain\"\n",
        "- âœ… **RÃ©duction des catÃ©gories** : Moins de variabilitÃ©\n",
        "- âœ… **Meilleure classification** : Groupes plus cohÃ©rents\n",
        "\n",
        "### Prochaines Ã‰tapes:\n",
        "1. **SÃ©paration train/test**: `train_test_split(X_selected, y)`\n",
        "2. **EntraÃ®nement de modÃ¨les**: RandomForest, XGBoost, etc.\n",
        "3. **Validation croisÃ©e**: Pour Ã©valuer la performance\n",
        "4. **Optimisation des hyperparamÃ¨tres**: GridSearch ou RandomSearch\n",
        "5. **Ã‰valuation finale**: MÃ©triques de performance\n",
        "\n",
        "### Utilisation Alternative - Analyse ComplÃ¨te:\n",
        "```python\n",
        "# Si vous voulez exÃ©cuter tout d'un coup (comme avant)\n",
        "analyzer = PropertyAnalyzer()\n",
        "results = analyzer.analyze_properties(df, target_column='price')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš€ Utilisation pour la ModÃ©lisation\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
