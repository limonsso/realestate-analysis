{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🏠 Exemple d'Analyse des Propriétés - Pipeline en 5 Étapes\n",
        "\n",
        "Ce notebook démontre l'utilisation de la fonction `analyze_properties` corrigée qui respecte les 5 étapes définies :\n",
        "\n",
        "1. **🧹 Nettoyage des données**\n",
        "   - Suppression des colonnes avec trop de valeurs manquantes\n",
        "   - Suppression des colonnes non pertinentes (IDs, liens, etc.)\n",
        "\n",
        "2. **🏷️ Classification des propriétés**\n",
        "   - Analyse du type de propriété (`type` column)\n",
        "   - Classification automatique : Résidentiel, Revenu, Autres\n",
        "\n",
        "3. **🔧 Préparation des données**\n",
        "   - Encodage des variables catégorielles\n",
        "   - Imputation des valeurs manquantes\n",
        "   - Normalisation si nécessaire\n",
        "\n",
        "4. **🎯 Sélection des variables**\n",
        "   - Méthode **Lasso** : Régularisation L1 pour éliminer les variables non significatives\n",
        "   - Méthode **Random Forest** : Importance des variables basée sur les arbres\n",
        "   - **Combinaison** des deux approches pour un résultat optimal\n",
        "\n",
        "5. **📊 Analyse des résultats**\n",
        "   - Statistiques par type de propriété\n",
        "   - Variables sélectionnées et leur importance\n",
        "   - Métriques de performance des modèles\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📥 Chargement des Données\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📊 Chargement des données depuis MongoDB\n",
        "from lib.db import read_mongodb_to_dataframe\n",
        "\n",
        "print(\"🔄 Connexion à MongoDB et chargement des données...\")\n",
        "\n",
        "# Chargement des propriétés vendues\n",
        "properties_db = read_mongodb_to_dataframe(\n",
        "    db='real_estate_db', \n",
        "    collection='properties', \n",
        "    query={'vendue': True},  # Filtre pour les propriétés vendues uniquement\n",
        "    no_id=False  # Garder l'ID pour référence\n",
        ")\n",
        "\n",
        "print(f\"✅ Données chargées avec succès!\")\n",
        "print(f\"📊 Nombre de propriétés: {len(properties_db):,}\")\n",
        "print(f\"📋 Nombre de colonnes: {len(properties_db.columns)}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔧 Configuration de l'Analyseur\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 📦 Import des classes modulaires\n",
        "from lib.property_analysis import (\n",
        "    PropertyAnalyzer, \n",
        "    PropertyDataProcessor, \n",
        "    PropertyClassifier, \n",
        "    FeatureSelector\n",
        ")\n",
        "\n",
        "print(\"📦 Classes modulaires importées avec succès!\")\n",
        "\n",
        "# Configuration du processeur de données\n",
        "data_processor = PropertyDataProcessor(\n",
        "    missing_threshold=0.05  # Supprimer les colonnes avec >95% de valeurs manquantes\n",
        ")\n",
        "\n",
        "# Configuration du classificateur de propriétés\n",
        "property_classifier = PropertyClassifier()\n",
        "\n",
        "# Configuration du sélecteur de variables\n",
        "feature_selector = FeatureSelector(\n",
        "    cv_folds=5,              # Validation croisée 5-folds\n",
        "    random_state=42,         # Reproductibilité\n",
        "    max_iter=10000,          # Convergence Lasso\n",
        "    tolerance=1e-3,          # Tolérance de convergence\n",
        "    rf_n_estimators=100,     # Nombre d'arbres Random Forest\n",
        "    rf_threshold=0.01        # Seuil d'importance des variables\n",
        ")\n",
        "\n",
        "# Création de l'analyseur principal avec injection de dépendances\n",
        "analyzer = PropertyAnalyzer(\n",
        "    data_processor=data_processor,\n",
        "    property_classifier=property_classifier,\n",
        "    feature_selector=feature_selector\n",
        ")\n",
        "\n",
        "print(\"✅ Analyseur configuré et prêt!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🚀 Exécution du Pipeline en 5 Étapes\n",
        "\n",
        "**Attention:** Cette cellule exécute maintenant la fonction `analyze_properties` corrigée qui respecte exactement les 5 étapes définies et résout les problèmes d'encodage des variables catégorielles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🚀 Exécution du pipeline complet d'analyse\n",
        "print(\"🔄 Lancement de l'analyse automatisée en 5 étapes...\")\n",
        "\n",
        "try:\n",
        "    # Exécution de l'analyse complète avec la fonction corrigée\n",
        "    results = analyzer.analyze_properties(properties_db, target_column='price')\n",
        "    \n",
        "    print(f\"\\n🎉 === PIPELINE TERMINÉ AVEC SUCCÈS ===\")\n",
        "    print(f\"✅ Toutes les 5 étapes ont été exécutées:\")\n",
        "    print(f\"   1. 🧹 Nettoyage des données\")\n",
        "    print(f\"   2. 🏷️ Classification des propriétés\")  \n",
        "    print(f\"   3. 🔧 Préparation des données\")\n",
        "    print(f\"   4. 🎯 Sélection des variables\")\n",
        "    print(f\"   5. 📊 Analyse des résultats\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur durante l'analyse: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Accès aux Résultats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎁 Variables disponibles pour les étapes suivantes\n",
        "if 'results' in locals():\n",
        "    X = analyzer.processed_data['X']\n",
        "    y = analyzer.processed_data['y']\n",
        "    df_classified = analyzer.processed_data['df_classified']\n",
        "    df_prepared = analyzer.processed_data['df_prepared']\n",
        "    important_features = results['selected_features']\n",
        "    \n",
        "    print(f\"📋 === RÉSULTATS DE L'ANALYSE ===\")\n",
        "    \n",
        "    # Forme des données\n",
        "    print(f\"\\n🏠 Transformation des données:\")\n",
        "    print(f\"   📊 Originales: {results['shape_original']}\")\n",
        "    print(f\"   📊 Traitées: {results['shape_processed']}\")\n",
        "    \n",
        "    # Classification des propriétés\n",
        "    print(f\"\\n🏷️ Classification des propriétés:\")\n",
        "    for category, count in results['classification_stats']['counts'].items():\n",
        "        pct = results['classification_stats']['percentages'][category]\n",
        "        print(f\"   🏠 {category}: {count:,} propriétés ({pct:.1f}%)\")\n",
        "    \n",
        "    # Variables sélectionnées\n",
        "    print(f\"\\n🎯 Variables sélectionnées:\")\n",
        "    print(f\"   📈 Total: {len(results['selected_features'])} variables\")\n",
        "    print(f\"   📝 Variables: {results['selected_features'][:10]}...\")  # Afficher les 10 premières\n",
        "    \n",
        "    # Importance des variables\n",
        "    if results['feature_importance']:\n",
        "        print(f\"\\n🌟 Top 5 des variables les plus importantes:\")\n",
        "        sorted_importance = sorted(results['feature_importance'].items(), key=lambda x: x[1], reverse=True)\n",
        "        for i, (feature, importance) in enumerate(sorted_importance[:5], 1):\n",
        "            print(f\"   {i}. {feature}: {importance:.4f}\")\n",
        "    \n",
        "    # Résumé final\n",
        "    summary = analyzer.get_summary()\n",
        "    print(f\"\\n📈 === RÉSUMÉ FINAL ===\")\n",
        "    print(f\"   🏠 Total propriétés: {summary['total_properties']:,}\")\n",
        "    print(f\"   📊 Features totales: {summary['total_features']}\")\n",
        "    print(f\"   🎯 Features sélectionnées: {summary['selected_features_count']}\")\n",
        "    print(f\"   📉 Réduction: {summary['reduction_percentage']:.1f}%\")\n",
        "    print(f\"   💰 Prix moyen: {summary['price_stats']['mean']:,.2f}$\")\n",
        "    \n",
        "    print(f\"\\n🔧 Variables disponibles pour la suite:\")\n",
        "    print(f\"   📊 X: Matrice des features ({X.shape})\")\n",
        "    print(f\"   🎯 y: Vecteur cible ({y.shape})\")\n",
        "    print(f\"   🏠 df_classified: DataFrame avec classification ({df_classified.shape})\")\n",
        "    print(f\"   🛠️  df_prepared: DataFrame préparé pour ML ({df_prepared.shape})\")\n",
        "    print(f\"   📝 important_features: Liste des variables importantes\")\n",
        "else:\n",
        "    print(\"❌ Aucun résultat disponible - L'analyse a probablement échoué\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📝 Améliorations Apportées\n",
        "\n",
        "### ✅ Corrections dans la Fonction `analyze_properties`\n",
        "\n",
        "1. **🧹 Structure des 5 Étapes Respectée**\n",
        "   - Réorganisation exacte selon vos spécifications\n",
        "   - Messages clairs pour chaque étape\n",
        "\n",
        "2. **🔧 Résolution du Problème d'Encodage**\n",
        "   - Vérification que toutes les variables sont numériques avant ML\n",
        "   - Conversion forcée des variables non-numériques avec `pd.to_numeric()`\n",
        "   - Suppression des colonnes qui ne peuvent pas être converties\n",
        "   - Imputation des NaN créés par la conversion\n",
        "\n",
        "3. **🛡️ Gestion d'Erreurs Robuste**\n",
        "   - Try-catch autour de la sélection de variables\n",
        "   - Fallback vers toutes les variables si sélection échoue\n",
        "   - Messages d'erreur informatifs\n",
        "\n",
        "4. **📊 Affichage Amélioré**\n",
        "   - Progress indicators pour chaque étape\n",
        "   - Statistiques détaillées des transformations\n",
        "   - Top 5 des variables les plus importantes\n",
        "\n",
        "### 🚀 Prochaines Étapes\n",
        "\n",
        "- Testez le notebook avec vos données\n",
        "- Ajustez les paramètres selon vos besoins\n",
        "- Utilisez `important_features` pour la modélisation\n",
        "- Adaptez les seuils de classification si nécessaire\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 📊 Analyse Immobilière - Étapes Individuelles\n",
        "\n",
        "Ce notebook montre comment exécuter chaque étape de l'analyse immobilière individuellement.\n",
        "Cela permet un meilleur contrôle et debugging de chaque étape du processus.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔧 Configuration et Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lib import PropertyAnalyzer, MongoDBLoader\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Option 1: Avec données MongoDB (recommandé)\n",
        "# loader = MongoDBLoader()\n",
        "# property_types = loader.load_property_types()\n",
        "# analyzer = PropertyAnalyzer(property_types_data=property_types)\n",
        "\n",
        "# Option 2: Avec données d'exemple pour la normalisation des types\n",
        "property_types_example = [\n",
        "    {\n",
        "        \"_id\": \"maison\",\n",
        "        \"display_names\": {\"fr\": \"Maison\", \"en\": \"House\"},\n",
        "        \"category\": \"Résidentiel\",\n",
        "        \"typical_characteristics\": [\"living_area\", \"lot_size\", \"bedrooms\", \"bathrooms\"]\n",
        "    },\n",
        "    {\n",
        "        \"_id\": \"condo\",\n",
        "        \"display_names\": {\"fr\": \"Condo\", \"en\": \"Condominium\"},\n",
        "        \"category\": \"Résidentiel\",\n",
        "        \"typical_characteristics\": [\"living_area\", \"bedrooms\", \"bathrooms\"]\n",
        "    },\n",
        "    {\n",
        "        \"_id\": \"duplex\",\n",
        "        \"display_names\": {\"fr\": \"Duplex\", \"en\": \"Duplex\"},\n",
        "        \"category\": \"Résidentiel\",\n",
        "        \"typical_characteristics\": [\"living_area\", \"lot_size\", \"bedrooms\", \"bathrooms\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# Option 3: Sans données de types (utilise la normalisation basique)\n",
        "# analyzer = PropertyAnalyzer()\n",
        "\n",
        "# Initialiser l'analyseur avec les données de types\n",
        "analyzer = PropertyAnalyzer(property_types_data=property_types_example)\n",
        "\n",
        "print(\"🏠 Analyseur immobilier initialisé avec succès!\")\n",
        "print(\"🔄 Normalisateur de types de propriétés configuré!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📥 Chargement des Données\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Option 1: Charger depuis MongoDB\n",
        "# loader = MongoDBLoader()\n",
        "# df = loader.load_properties()\n",
        "# property_types = loader.load_property_types()\n",
        "\n",
        "# Option 2: Charger depuis un fichier CSV/Excel\n",
        "# df = pd.read_csv('votre_fichier.csv')\n",
        "\n",
        "# Option 3: Utiliser des données d'exemple (pour test)\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'price': np.random.normal(500000, 150000, n_samples),\n",
        "    'living_area': np.random.normal(1500, 400, n_samples),\n",
        "    'lot_size': np.random.normal(5000, 2000, n_samples),\n",
        "    'bedrooms': np.random.randint(1, 6, n_samples),\n",
        "    'bathrooms': np.random.randint(1, 4, n_samples),\n",
        "    'year_built': np.random.randint(1950, 2024, n_samples),\n",
        "    'type': np.random.choice(['maison', 'condo', 'duplex'], n_samples),\n",
        "    'city': np.random.choice(['Montreal', 'Quebec', 'Laval', 'Gatineau'], n_samples),\n",
        "    'region': np.random.choice(['Montreal', 'Quebec', 'Outaouais'], n_samples),\n",
        "    'building_style': np.random.choice(['contemporain', 'traditionnel', 'moderne'], n_samples),\n",
        "    'municipal_evaluation_total': np.random.normal(450000, 120000, n_samples),\n",
        "    # Colonnes à supprimer (simulation données MongoDB)\n",
        "    '_id': range(n_samples),\n",
        "    'link': ['http://example.com'] * n_samples,\n",
        "    'images': [['img1.jpg', 'img2.jpg']] * n_samples,\n",
        "    'extraction_metadata': [{'date': '2024-01-01'}] * n_samples\n",
        "})\n",
        "\n",
        "# Ajouter quelques valeurs manquantes\n",
        "df.loc[df.sample(50).index, 'lot_size'] = np.nan\n",
        "df.loc[df.sample(30).index, 'year_built'] = np.nan\n",
        "\n",
        "print(f\"📊 Données chargées: {df.shape}\")\n",
        "print(f\"📝 Colonnes: {list(df.columns)}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 ÉTAPE 1: Validation et Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valider et explorer les données\n",
        "df_step1 = analyzer.validate_and_explore(df, target_column='price')\n",
        "\n",
        "# Vous pouvez ajouter votre propre exploration ici\n",
        "print(\"\\n🔍 Exploration supplémentaire:\")\n",
        "print(f\"Types de données:\")\n",
        "print(df_step1.dtypes)\n",
        "\n",
        "print(f\"\\nValeurs manquantes par colonne:\")\n",
        "print(df_step1.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🧹 ÉTAPE 2: Nettoyage des Données\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nettoyer les données\n",
        "df_step2 = analyzer.clean_data(df_step1)\n",
        "\n",
        "print(\"\\n🔍 Vérification après nettoyage:\")\n",
        "print(f\"Colonnes restantes: {list(df_step2.columns)}\")\n",
        "print(f\"Forme des données: {df_step2.shape}\")\n",
        "\n",
        "df_step2.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔄 ÉTAPE 3: Normalisation des Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normaliser les variables catégorielles\n",
        "df_step3 = analyzer.normalize_variables(df_step2)\n",
        "\n",
        "print(\"\\n🔍 Vérification après normalisation:\")\n",
        "print(f\"Colonnes: {list(df_step3.columns)}\")\n",
        "\n",
        "# Vérifier les changements dans les variables catégorielles\n",
        "categorical_cols = df_step3.select_dtypes(include=['object']).columns\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n📊 Variable '{col}':\")\n",
        "    print(f\"   Valeurs uniques: {df_step3[col].nunique()}\")\n",
        "    print(f\"   Valeurs: {list(df_step3[col].unique())}\")\n",
        "\n",
        "df_step3.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔢 ÉTAPE 4: Encodage des Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encoder les variables catégorielles\n",
        "df_step4 = analyzer.encode_features(df_step3)\n",
        "\n",
        "print(\"\\n🔍 Vérification après encodage:\")\n",
        "print(f\"Nouvelles colonnes: {list(df_step4.columns)}\")\n",
        "print(f\"Types de données après encodage:\")\n",
        "print(df_step4.dtypes)\n",
        "\n",
        "df_step4.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔧 ÉTAPE 5: Imputation des Valeurs Manquantes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imputer les valeurs manquantes\n",
        "df_step5 = analyzer.impute_missing_values(df_step4)\n",
        "\n",
        "print(\"\\n🔍 Vérification après imputation:\")\n",
        "print(f\"Valeurs manquantes restantes: {df_step5.isnull().sum().sum()}\")\n",
        "print(f\"Statistiques des colonnes imputées:\")\n",
        "print(df_step5.describe())\n",
        "\n",
        "df_step5.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🏠 ÉTAPE 6: Classification des Propriétés\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classifier les propriétés\n",
        "df_step6 = analyzer.classify_properties(df_step5)\n",
        "\n",
        "print(\"\\n🔍 Vérification de la classification:\")\n",
        "print(f\"Nouvelle colonne: 'classification_immobiliere'\")\n",
        "print(f\"Distribution des classifications:\")\n",
        "print(df_step6['classification_immobiliere'].value_counts())\n",
        "\n",
        "# Visualiser la distribution des prix par classification\n",
        "print(\"\\n💰 Prix moyen par catégorie:\")\n",
        "price_by_class = df_step6.groupby('classification_immobiliere')['price'].agg(['mean', 'median', 'count'])\n",
        "print(price_by_class)\n",
        "\n",
        "df_step6.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎯 ÉTAPE 7: Préparation pour la Modélisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Préparer les données pour la modélisation\n",
        "X, y = analyzer.prepare_for_modeling(df_step6, target_column='price')\n",
        "\n",
        "print(\"\\n🔍 Vérification des données préparées:\")\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "print(f\"\\nColonnes features:\")\n",
        "for i, col in enumerate(X.columns, 1):\n",
        "    print(f\"  {i}. {col}\")\n",
        "\n",
        "print(f\"\\nStatistiques de la variable cible:\")\n",
        "print(y.describe())\n",
        "\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎯 ÉTAPE 8: Sélection de Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sélectionner les variables importantes\n",
        "selected_features = analyzer.select_features(X, y)\n",
        "\n",
        "print(\"\\n🔍 Analyse des variables sélectionnées:\")\n",
        "print(f\"Variables sélectionnées: {selected_features}\")\n",
        "\n",
        "# Créer un sous-ensemble avec seulement les variables sélectionnées\n",
        "X_selected = X[selected_features]\n",
        "print(f\"\\nNouveaux features (X_selected): {X_selected.shape}\")\n",
        "\n",
        "X_selected.head()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🏠 ÉTAPE 9: Sélection par Type de Propriété\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sélectionner les variables par type de propriété\n",
        "classification_features = analyzer.select_features_by_classification(\n",
        "    X, y, df_step6['classification_immobiliere']\n",
        ")\n",
        "\n",
        "print(\"\\n🔍 Analyse des variables par type:\")\n",
        "if classification_features:\n",
        "    for prop_type, features in classification_features.items():\n",
        "        print(f\"\\n🏷️ {prop_type}:\")\n",
        "        print(f\"   Variables importantes: {features}\")\n",
        "        \n",
        "        # Créer un sous-ensemble pour ce type\n",
        "        mask = df_step6['classification_immobiliere'] == prop_type\n",
        "        X_type = X[mask][features]\n",
        "        y_type = y[mask]\n",
        "        print(f\"   Données pour ce type: X={X_type.shape}, y={y_type.shape}\")\n",
        "else:\n",
        "    print(\"Pas de sélection spécifique par type disponible\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 ÉTAPE 10: Importance des Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer l'importance des variables\n",
        "feature_importance = analyzer.calculate_feature_importance(X, y)\n",
        "\n",
        "print(\"\\n🔍 Analyse détaillée de l'importance:\")\n",
        "importance_df = pd.DataFrame([\n",
        "    {'feature': feature, 'importance': importance}\n",
        "    for feature, importance in feature_importance.items()\n",
        "]).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n📊 Tableau d'importance complet:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Visualisation simple\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_features = importance_df.head(10)\n",
        "plt.barh(range(len(top_features)), top_features['importance'])\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 10 Variables les Plus Importantes')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🏆 ÉTAPE 11: Résumé Final\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Générer le résumé final\n",
        "final_results = analyzer.final_summary()\n",
        "\n",
        "print(\"\\n📋 Résultats structurés:\")\n",
        "print(f\"Résultats disponibles: {final_results.keys()}\")\n",
        "\n",
        "# Créer un DataFrame de résumé\n",
        "summary_data = {\n",
        "    'Métrique': [\n",
        "        'Lignes originales',\n",
        "        'Lignes après traitement',\n",
        "        'Colonnes originales',\n",
        "        'Colonnes après traitement',\n",
        "        'Variables sélectionnées',\n",
        "        'Taux de conservation des variables'\n",
        "    ],\n",
        "    'Valeur': [\n",
        "        final_results.get('shape_original', (0, 0))[0],\n",
        "        final_results.get('shape_processed', (0, 0))[0],\n",
        "        final_results.get('shape_original', (0, 0))[1],\n",
        "        final_results.get('shape_processed', (0, 0))[1],\n",
        "        len(final_results.get('selected_features', [])),\n",
        "        f\"{(len(final_results.get('selected_features', [])) / (final_results.get('shape_processed', (0, 1))[1] - 1) * 100):.1f}%\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(\"\\n📊 Tableau de résumé:\")\n",
        "print(summary_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Maintenant vous avez toutes les données prêtes pour la modélisation\n",
        "print(\"🎯 Données prêtes pour la modélisation:\")\n",
        "print(f\"\\n📊 X (features complètes): {X.shape}\")\n",
        "print(f\"📊 X_selected (features sélectionnées): {X_selected.shape}\")\n",
        "print(f\"🎯 y (target): {y.shape}\")\n",
        "print(f\"🏠 df_step6 (données complètes avec classification): {df_step6.shape}\")\n",
        "\n",
        "print(f\"\\n✅ Variables sélectionnées pour la modélisation:\")\n",
        "for i, feature in enumerate(selected_features, 1):\n",
        "    print(f\"  {i}. {feature}\")\n",
        "\n",
        "print(f\"\\n🏷️ Classifications disponibles:\")\n",
        "for category, stats in final_results.get('classification_stats', {}).get('counts', {}).items():\n",
        "    print(f\"  • {category}: {stats} propriétés\")\n",
        "\n",
        "print(\"\\n🎉 Prêt pour l'entraînement de modèles!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📝 Notes et Prochaines Étapes\n",
        "\n",
        "### Données Disponibles:\n",
        "- `X`: Matrice complète des features\n",
        "- `X_selected`: Matrice avec seulement les features sélectionnées\n",
        "- `y`: Vecteur target (prix)\n",
        "- `df_step6`: DataFrame complet avec classification\n",
        "- `selected_features`: Liste des variables importantes\n",
        "- `classification_features`: Variables par type de propriété\n",
        "- `feature_importance`: Importance de chaque variable\n",
        "\n",
        "### Méthodes Disponibles (Noms Simplifiés):\n",
        "1. **`validate_and_explore()`** - Validation et exploration des données\n",
        "2. **`clean_data()`** - Nettoyage et suppression des colonnes inutiles\n",
        "3. **`normalize_variables()`** - 🆕 Standardisation des variables catégorielles\n",
        "4. **`encode_features()`** - Transformation en variables numériques\n",
        "5. **`impute_missing_values()`** - Traitement des valeurs manquantes\n",
        "6. **`classify_properties()`** - Catégorisation des propriétés\n",
        "7. **`prepare_for_modeling()`** - Séparation features/target\n",
        "8. **`select_features()`** - Sélection des variables importantes\n",
        "9. **`select_features_by_classification()`** - Variables spécifiques par catégorie\n",
        "10. **`calculate_feature_importance()`** - Calcul des scores d'importance\n",
        "11. **`final_summary()`** - Synthèse complète\n",
        "\n",
        "### Utilisation Simplifiée:\n",
        "```python\n",
        "# Option 1: Avec normalisation avancée des types (recommandé)\n",
        "from lib import MongoDBLoader\n",
        "loader = MongoDBLoader()\n",
        "property_types = loader.load_property_types()\n",
        "analyzer = PropertyAnalyzer(property_types_data=property_types)\n",
        "\n",
        "# Option 2: Avec données d'exemple\n",
        "property_types_example = [\n",
        "    {\"_id\": \"maison\", \"display_names\": {\"fr\": \"Maison\", \"en\": \"House\"}},\n",
        "    {\"_id\": \"condo\", \"display_names\": {\"fr\": \"Condo\", \"en\": \"Condominium\"}}\n",
        "]\n",
        "analyzer = PropertyAnalyzer(property_types_data=property_types_example)\n",
        "\n",
        "# Option 3: Sans normalisation avancée (fallback)\n",
        "analyzer = PropertyAnalyzer()\n",
        "\n",
        "# Utilisation standard\n",
        "df_step1 = analyzer.validate_and_explore(df, target_column='price')\n",
        "df_step2 = analyzer.clean_data(df_step1)\n",
        "df_step3 = analyzer.normalize_variables(df_step2)  # 🆕 Utilise PropertyTypeNormalizer\n",
        "df_step4 = analyzer.encode_features(df_step3)\n",
        "df_step5 = analyzer.impute_missing_values(df_step4)\n",
        "df_step6 = analyzer.classify_properties(df_step5)\n",
        "X, y = analyzer.prepare_for_modeling(df_step6, target_column='price')\n",
        "selected_features = analyzer.select_features(X, y)\n",
        "classification_features = analyzer.select_features_by_classification(X, y, df_step6['classification_immobiliere'])\n",
        "feature_importance = analyzer.calculate_feature_importance(X, y)\n",
        "final_results = analyzer.final_summary()\n",
        "```\n",
        "\n",
        "### Avantages des Nouveaux Noms:\n",
        "- ✅ **Plus intuitifs** : Noms descriptifs au lieu de step_1, step_2...\n",
        "- ✅ **Plus lisibles** : Code plus facile à comprendre\n",
        "- ✅ **Plus maintenables** : Fonctions clairement identifiées\n",
        "- ✅ **Auto-documentés** : Le nom explique la fonction\n",
        "\n",
        "### Avantages de la Nouvelle Normalisation:\n",
        "\n",
        "#### 🏠 **PropertyTypeNormalizer (Nouveau)**:\n",
        "- ✅ **Normalisation intelligente** : Utilise la collection `property_types` MongoDB\n",
        "- ✅ **Correspondance approximative** : \"Maison à vendre\" → \"maison\"\n",
        "- ✅ **Support multilingue** : FR/EN automatique\n",
        "- ✅ **Types inconnus gérés** : Marqués comme \"unknown\"\n",
        "- ✅ **Extensible** : Facilement personnalisable\n",
        "- ✅ **ID normalisés** : Crée une colonne `type_id` standardisée\n",
        "\n",
        "#### 🏙️ **Autres Variables**:\n",
        "- ✅ **Villes corrigées** : \"Montreal\" → \"Montréal\"\n",
        "- ✅ **Régions standardisées** : \"Monteregie\" → \"Montérégie\"\n",
        "- ✅ **Styles uniformisés** : \"contemporary\" → \"contemporain\"\n",
        "- ✅ **Réduction des catégories** : Moins de variabilité\n",
        "- ✅ **Meilleure classification** : Groupes plus cohérents\n",
        "\n",
        "### Prochaines Étapes:\n",
        "1. **Séparation train/test**: `train_test_split(X_selected, y)`\n",
        "2. **Entraînement de modèles**: RandomForest, XGBoost, etc.\n",
        "3. **Validation croisée**: Pour évaluer la performance\n",
        "4. **Optimisation des hyperparamètres**: GridSearch ou RandomSearch\n",
        "5. **Évaluation finale**: Métriques de performance\n",
        "\n",
        "### Utilisation Alternative - Analyse Complète:\n",
        "```python\n",
        "# Si vous voulez exécuter tout d'un coup (comme avant)\n",
        "analyzer = PropertyAnalyzer()\n",
        "results = analyzer.analyze_properties(df, target_column='price')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🚀 Utilisation pour la Modélisation\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
